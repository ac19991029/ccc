# Amie: association rule mining under incomplete evidence in ontological knowledge bases

# AMIE:本体知识库中不完全证据下的关联规则挖掘

信息提取的最新进展导致了巨大的知识库(KBs)，它以机器可读的格式捕获知识。归纳逻辑编程(ILP)可用于从知识库中挖掘逻辑规则。这些规则可以帮助推断并将缺失的知识添加到知识库。虽然ILP是一个成熟的领域，但是从KBs挖掘逻辑规则在两个方面有所不同:首先，当前的规则挖掘系统很容易被大量的数据所淹没(最先进的系统甚至不能在今天的KBs上运行)。其次，ILP通常需要反例。但是KBs采用了开放世界假设(OWA)，即没有数据的情况不能作为反例。

在这篇论文中，我们开发了一个规则挖掘模型，它是明确地定制来支持OWA场景。该方法受关联规则挖掘的启发，提出了一种新的置信度方法。我们广泛的实验表明，我们的方法在精度和覆盖范围方面优于最先进的方法。此外，我们的系统AMIE，挖掘规则的速度比最先进的方法快几个数量级。

## Related work

近年来，出现了各种大型知识库，如cyc、yago、DBpedia、freebase，这些KBs提供了各种各样的实体信息。

但是，即使是这样的大型KBs也没有完成。其中一些是从自然语言资源中提取出来的，这些资源不可避免地会显示出差距。其他的是手动创建和扩展的。要完成这些KBs，需要付出很大的努力来提取事实、检查它们的正确性，并将它们添加到知识库。但是，KBs本身往往已经包含了足够的信息，可以推导和添加新的事实。

在绝大多数情况下，规则是有效的。找到这些规则有四个目的:首先，通过在数据上应用这些规则，可以派生出新的事实，使知识库更完整。其次，这些规则可以识别知识库中潜在的错误。例如，如果知识库包含一个完全不相干的人是一个孩子的父亲的声明，那么这个声明可能是错误的。第三，规则可以用于推理。许多推理方法依赖于其他方提供规则(例如，[27,31])。最后，描述一般规律的规则可以帮助我们更好地理解数据。

本文目标是从KBs中挖掘出一些规则，在语义网的精神下关注rdf风格的KBs。这些KBs以三元组的形式提供二进制关系，并只包含肯定语句。此外，他们在开放世界假设(OWA)下运作。在OWA下，没有包含在国民议会的声明并不一定是错误的;它只是未知。这是许多在封闭世界假设(CWA)下操作的标准数据库设置的关键区别。

从给定数据集挖掘规则是一个由来已久的问题。它是在关联规则挖掘和归纳逻辑规划(ILP)的背景下进行研究的。关联规则挖掘[3]在销售数据库上下文中是众所周知的。它可以找到一些规则，比如“如果客户买了啤酒和葡萄酒，那么他也买了阿司匹林”。这种规则的可信度是啤酒和葡萄酒实际上与阿司匹林同时购买的情况的比率。关联规则挖掘**本质**上实现了一个封闭世界的假设:预测不存在于数据库中的新条目的规则具有较低的可信度。它不能用于(也不打算用于)向数据库添加新项。

ILP方法从基本事实推导出逻辑规则。然而，目前的ILP系统不能应用于语义KBs，原因有二:首先，它们通常需要负面陈述作为反例。但语义KBs通常不包含负面的内容。RDF的语义太弱，不能从KBs的事实推断出负面证据，因为OWA，缺席的陈述不能作为反证据。其次，目前的ILP系统速度很慢，无法处理KBs提供的大量数据。

关联规则挖掘的一个问题是，对于某些应用程序，支持度和置信度的标准度量不能产生良好的结果。[36]讨论了一些用于测量一般规则的兴趣度的替代方法。我们的方法受到了这项工作的启发，并且我们也利用了语言偏向来减少搜索空间。Sherlock[32]是一种无监督的ILP方法，用于从一组为给定目标关系提取的事实中学习一阶Horn子句。它使用概率图形模型(PGMs)来推断新的事实。它通过在预处理步骤中进行广泛过滤，并在推理部分惩罚较长的规则来处理所提取事实的噪声。为了挖掘规则，Sherlock使用了两种启发式:统计显著性和统计相关性。 WARMR系统使用声明性语言来减少搜索空间ALEPH采用多种规则评估函数和多种搜索策略，测试发现这些系统挖掘的规则少且慢。

额外规则挖掘 提出了另一种基于RDF数据[28]的规则挖掘方法，以发现基于RDF的医疗数据中的因果关系。它需要一个领域专家来定义挖掘过程的目标和上下文，以便生成正确的事务。我们的不依赖用户来定义任何上下文或目标，可以开箱即用。

本文中，我们的目标是在一个知识库上生成Horn规则。其他方法使用规则挖掘来生成知识库的模式或分类法。[7]采用基于上下文向量和形式概念分析的聚类技术来构建分类法。

## Preliminaries

本文主要研究RDF知识库。可以将RDF KB视为一组事实，其中每个事实都是形式为x、r、y的三元组，其中x表示主语，r表示关系(或谓词)，y表示事实的宾语。对事实有几种等价的替代表述;在本文中，我们使用一种逻辑符号，将一个事实表示为r(x, y)。

RDF KB的事实通常可以分为ABox和T-Box。A-Box包含实例数据，而T-Box是定义类、域、谓词范围和类层次结构的事实的子集。虽然我们的挖掘方法也可以使用TBox信息，但我们主要关注的是A-Box，即一个特定实体与另一个实体相关的事实集。

原子是一个在主体和/或客体位置上可以有变量的事实。(Horn)规则由头和体组成，头是单个原子，体是一组原子。我们用头r(x, y)和体{B1，…， Bn}通过暗示

![image-20230417172601066](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230417172601066.png)

与大多数ILP系统一样，AMIE使用一种语言偏向来限制搜索空间。如果规则中的两个原子共享一个变量或一个实体，我们就说它们是连接的。如果每个原子都以可传递的方式连接到规则的每个其他原子，则该规则就是连接的。AMIE只挖掘连接的规则，也就是说，它避免构造包含不相关原子的规则。如果规则中的每个变量至少出现两次，则该规则是封闭的。这样的规则不仅预测一个事实的存在(例如diedIn(x, y))∃z: wasBornIn(x, z))，而且还能给出具体的论据(例如diedIn(x, y)的宗是bornin (x, y))。AMIE只挖掘封闭的规则。我们允许在主体中包含头部关系的递归规则。

关联规则挖掘不能直接用于horn规则的挖掘

## 挖掘模型

我们区分4种类型的事实:知识库已知的真事实(KBtrue)，知识库未知的真事实(NEWtrue)，知识库已知的假事实(KBfalse)，以及知识库未知的假事实(NEWfalse)。规则将做出特定的预测(蓝色圆圈)。这些预测可以被认为是正确的(A)、错误的(C)或未知的(B和D)。当它们不为知识库所知时，它们仍然可以是正确的(B)或错误的(D)。

![image-20230418135822599](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230418135822599.png)

我们的目标是找到能够做出超越当前KB的真实预测的规则。在图中，我们希望最大化区域B，最小化区域d。在我们的环境中有两个明显的挑战:首先，区域NEWtrue和NEWfalse是未知的。所以如果我们想以牺牲D为代价来最大化B，我们就在KB之外的区域操作。我们希望使用面积KBtrue和KBfalse来估计未知区域。然而，这导致了第二个挑战:语义KBs不包含负面证据。因此，kbff区域是空的。我们现在将提出应对这些挑战的不同措施。规则的支持量化了正确预测的数量，即a的大小。有几种方法来定义支持:它可以是出现在知识库中的规则的实例化数量。这就是我们对关联规则挖掘[3]的类比所表明的(第3节)。然而，如果我们向主体添加原子，这个度量就不是单调的了。

头部覆盖。支持是一个绝对的数字。这意味着需要支持阈值的用户必须知道KB的绝对大小，才能给出有意义的值。为了避免这种情况，我们还定义了一个比例版本的支持。一种简单的方法是在KB大小上使用上一段中定义的支持的绝对数量。然而，在这种情况下，没有很多事实的关系(要么是因为知识库的不完整性，要么是因为它们的性质)将不会在规则的头部被考虑，也就是说，我们将不会学习预测这种关系的规则。因此，我们建议使用头部覆盖的概念。这是由规则的预测所覆盖的来自头部关系的成对的比例

我们设置的主要挑战是为规则挖掘提供反例。这些可以起到KBfalse的作用，这样我们就可以估计NEWtrue和NEWfalse的区域。有几种方法可以解决这个问题:**标准置信度**、标准纯正学习评价分数以及我们新的部分完备性假设。

## AMIE

我们的目标是挖掘第3节中定义的表单规则。任何一种挖掘方法的主要问题之一就是寻找一种有效的方法来探索搜索空间。枚举所有可能规则的朴素算法对于大型KBs是不可行的。因此，我们通过挖掘操作符迭代地扩展规则来探索搜索空间。

我们把规则看作是原子的序列。第一个原子是头原子，其余的是身体原子。在遍历搜索空间的过程中，我们可以使用以下操作符之一来扩展规则:

该操作符为规则添加一个新的原子。这个新原子为它的两个参数之一使用了一个新的变量。另一个参数(变量或实体)与规则共享，也就是说，它出现在规则的其他原子中。

这个操作符将一个新的原子添加到一个规则中，该规则使用一个实体作为一个参数，并与规则共享另一个参数(变量或实体)

添加关闭原子(OC)这个操作符向规则添加一个新的原子，以便它的两个参数都与规则共享。

我们使用算法1挖掘规则。该算法维护一个规则队列，该队列最初只包含空规则。该算法迭代地将规则从队列中取出。如果规则是关闭的(参见第3节)，则输出规则，否则不输出。然后，算法对规则应用所有操作符，并将产生的规则添加到队列中(除非它们被删除，s.b.)。重复这个过程，直到队列为空。我们通过维护一个集中的队列来并行化这个过程，线程从这个队列出队和入队。我们不将规则的预测返回到知识库。所有度量(例如置信度和支持度)总是在原始KB上计算。

![image-20230418141506715](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230418141506715.png)

算法2展示了我们如何回答投影查询。该算法以一个选择变量?x、一个投影原子H = R(x, Y)、剩余原子B1，…Bn，一个常数k，和一个KB k，我们首先检查x是否出现在投影原子中。如果是这种情况，我们将遍历投影原子的所有实例化，相应地实例化查询，并检查是否存在。每个现有的实例化都会增加?x的值。返回所有计数器超过k的值。如果选择变量没有出现在投影原子中，则遍历投影原子的所有实例化。我们相应地实例化查询，并为?x触发一个SELECT查询。每增加一个?x的值，计数器就增加。我们报告所有计数器超过k的值。

![image-20230418152340924](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230418152340924.png)

我们将投影查询确定为规则挖掘的关键查询类型。

## 实验

我们进行了三组实验:在第一组中，我们将AMIE与两种流行的、最先进的公开可用系统WARMR[11,12]和ALEPH4进行了比较。在第二组实验中，我们将标准置信度与我们在本文(第4节)中引入的新PCA置信度进行比较。在第三组实验中，我们在不同的数据集上运行AMIE来显示系统的适用性。

我们在不同的KBs上进行实验。在所有情况下，我们都删除了rdf:type关系，因为它会扩大KBs的大小。我们知道rdf:type关系对规则挖掘非常有帮助。然而，目前没有任何方法(包括我们的)具体使用它。我们计划在未来的工作中利用它。此外，我们从KBs中删除了所有带有文字(数字和字符串)的事实。文字值(例如地理坐标)只由很少的实体共享，这使得它们对规则挖掘不那么有趣。

我们将AMIE与WARMR和ALEPH进行比较。对于每个系统，我们进行了3个实验:我们首先比较竞争对手系统和AMIE系统的可用性。然后，比较它们的运行时间。最后，我们比较它们的产出。

WARMR是一个集ILP和关联规则挖掘于一体的系统。与APRIORI算法类似，它执行宽度优先搜索以找到频繁的模式为了发现频繁模式(就像在关联规则挖掘中一样)，我们需要有频率的概念。WARMR将查询视为模式，并且查询可以包含变量，所以给定查询的频率并不是很明显。因用户需要指定由系统统计的谓词(键谓词)。由于键谓词决定了计算的内容，因此必须将其包含在所有查询中。因此，我们添加一个谓词实体(x)，用KB的所有实体填充它。AMIE不需要这样的选择。对于WARMR，用户需要提供关于哪些谓词可以添加到查询的特定信息，哪些变量可以是新鲜的，哪些谓词的参数可以是统一的(类型声明)。相比之下，AMIE不需要这些。AMIE只接受三种格式的KB作为输入。

我们得出结论，WARMR更广泛的任务和更广泛的适用性需要更多的配置、了解和专家知识，以使其在语义KBs中挖掘Horn规则。

## conclude

本文提出了一种基于RDF知识库的Horn规则挖掘方法。我们引入了一个开放世界假设下的规则挖掘的形式化模型，一个模拟反例的新方法，以及一个可扩展的挖掘算法。与最先进的方法相比，我们的系统(AMIE)不需要KB以外的输入，也不需要配置或参数调优。正如我们的大量实验所显示的那样，AMIE在几分钟内运行在数百万个事实上，不仅在运行时间上，而且在输出规则的数量和质量上都优于最先进的方法。我们的信心测度能够合理地预测规则的精度。在我们未来的工作中，我们还计划考虑知识库的T-Box，以产生更精确的规则。我们还致力于探索当多个规则预测相同的事实时的协同效应，并扩展霍恩规则之外的规则集，从而可以预测更复杂的事实和隐藏的知识。