# Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification

# 零样本关系分类的逻辑引导语义表示学习

computation and language：期刊

关系分类的目的是从句子中提取实体对之间的语义关系，现如今大部分现有的方式只能识别在训练期间发生的可见的关系类。本文研究零样本关系分类来测试不可见的关系类。以往的研究将关系类型的理解问题视为阅读理解问题或文本蕴涵问题，必须依靠人工描述信息来提高关系类型的可理解性。因此，忽略了关系标签的丰富语义知识。本文提出了一种新的基于逻辑引导的零镜头关系分类语义表示学习模型。我们的方法通过知识图嵌入和逻辑规则的隐式和显式语义表示，在可见和不可见关系之间建立联系。大量的实验结果表明，该方法可以推广到不可见的关系类型，并取得了很好的改进效果。

#### 关系分类（RC）应用：

知识库建设（Luan et al.， 2018）、知识问答（Yu et al.， 2017)

在现实世界中，存在着大量的细粒度关系，标记的关系类型是有限的，每一种类型通常都有一定数量的标记样本，在传统模型中，当没有训练例子的类型预测时即出现新的关系，模型将失效，所以迫切需要零样本关系分类的模型。

#### 前人研究：

通过阅读理解（Levy et al.， 2017)、文本蕴涵(Obamuyide and Vlachos, 2018)等方法利用迁移学习过程。

#### 局限性：

必须依靠人工描述信息来提高关系类型的可理解性

#### 本文创新点：

受计算机视觉中零样本学习启发，通过投影函数学习从输入样本的特征空间到语义空间进行映射。这个是为了在可见和不可见的关系之间建立语义联系。

传统的方法通常利用标签的词嵌入作为公共语义空间。

本文认为关系标签空间中忽略了丰富的语义知识：

1 知识图嵌入的隐式语义连接。Yang et al.， 2014)表明，语义相似关系的知识图嵌入(Knowledge Graph Embeddings, KGEs)在潜在空间中彼此相邻。例如：居住地点和国籍关系相关性大于职业和居住地，可以利用kg知识在可见和不可见之间建立联系。

2 规则学习的显示予以连接。根据符号推理识别出看不见的关系。

#### 本文内容：

提出一种新的零样本关系分类方法，逻辑引导语义表示学习（LSRL）。首先利用预先训练的知识图嵌入，如transE构建隐式语义连接。kgE将实体和关系嵌入到一个连续的语义向量空间，捕获语义空间中关系之间的语义连接。接下来利用AMIE（Gal´arraga等人，2013）从知识图中挖掘出的逻辑规则，并引入规则引导的表示学习来获得明确的语义连接。本文的方法与模型无关，所以与现有的方法是正交的，本文将自己的方法与两种著名的零样本方法相结合即DeViSE(Frome et al.， 2013)和ConSENorouzi et al.， 2013).

## Related work

#### 关系分类

关系分类旨在通过特定的上下文预测两个实体之间的关系。传统解决的方法有GuoDong et al.， 2005，深度神经网络方法如(Zeng et al.， 2015;Zhang et al.， 2018;Zhang et al.， 2019a;Deng et al.， 2020a;邓等人，2020b;Zhang et al.， 2020a;Zhang et al.， 2020b;Yu等人，2020年;Wang et al.， 2020)，以及一些联合模型(Zheng et al.， 2017;叶等人，2020)。这些都是有监督的方法，只能推断存在于列集中的关系，不能对新添加的关系进行预测。

#### 零样本分类

零样本关系分类最早由Levy et al.提出，将关系分类简化为阅读理解问题，从而提取新的关系。(Obamuyide and Vlachos, 2018)将关系抽取作为一种文本蕴涵问题，并将输入实例和关系描述作为前提和假设。然而这些方法需要人为注释器构造问题或为关系编写描述，这是劳动密集型的。本文提出的分类方法不需要人工操作。 

ZSL的关键是利用可见类和不可见类之间的共享语义表示，并将其转换为样本的可视化表示。(Frome et al.， 2013)提出了一种名为“设计”的ZSL模型，使用一种高效的排序损失公式学习图像特征和语义空间之间的线性映射。(Norouzi et al.， 2013)提出了ConSE，它首先预测见过的类后，然后考虑最可能见过的类的顶部T的凸组合，将图像特征投影到word2vec空间。这些方法的语义表示是通过附加在类标签上的某些辅助信息来学习的，如属性描述、嵌入表示。本文则是通过知识图中的信息来构建语义空间，而不是考虑词的嵌入或属性。

也有ZSL应用于NLP，如事件提取(Huang et al.， 2017)，实体类型(Zhou et al.， 2018)，跨语言实体链接(Rijhwani et al.， 2018)，文本分类(Pushp and Srivastava, 2017)和冷启动推荐(Li et al.， 2019)，以及KG，如链接预测(Qin et al.， 2020)。

#### 知识图谱嵌入

基于翻译、语义匹配和神经网络的ｋｇ嵌入方法被设计出来学习ｋｇ实体的向量表示和ｋｇ关系。基于翻译的模型(Bordes et al.， 2013;Ji等人，2015;Lin等人，2015b)使用基于距离的评分函数来评估三垒的合理性。语义匹配模型(Yang et al.， 2014;镍等，2016;Liu et al.， 2017)使用基于相似度的评分函数来计算关系三元组的能量，其中代表模型DistMult (Yang et al.， 2014)的评分函数为fr(h, t) = hdiag(Mr)t。神经网络模型学习通过神经网络表达实体和关系，例如基于cnn的方法(detttmers等人，2018)和基于gnn的方法(Schlichtkrull等人，2018)。本文利用ｋｇ嵌入模型来学习关系的表示，而不是单词嵌入，从而使关系的表示只与ｋｇ的结构相关与关系的名称无关。

#### 规则学习

ｋｇ上的规则可以捕获关系之间的连接，有多种规则学习方法，如归纳逻辑规划算法（ILP）、规则挖掘方法和基于嵌入的方法。ILP由一阶逻辑进行形式化，具有强表示能力，但不能扩展到大型数据集。为解决此问题，开发了几种ｋｇｓ规则挖掘器如语义匹配模型(Yang et al.， 2014;镍等，2016;Liu et al.， 2017)使用基于相似度的评分函数来计算关系三元组的能量，其中代表模型DistMult (Yang et al.， 2014)的评分函数为fr(h, t) = hdiag(Mr)t。神经网络模型学习通过神经网络表达实体和关系，例如基于cnn的方法(detttmers等人，2018)和基于gnn的方法(Schlichtkrull等人，2018)。此外RLvLR (Omran et al.， 2018)利用嵌入来指导规则提取和减少搜索空间。DistMult (Yang et al.， 2014)利用学习后的实体和关系嵌入来提取逻辑规则。并且(Ho et al.， 2018)引入了一个由外部资源指导的规则学习框架。本文采用(Gal´arraga et al.， 2013)中广泛使用的规则挖掘方法从KG中提取规则。

## Methodology

定义符号术语。ｒｓ为训练时可见的关系集合。ｒｕ为不可见的集合。ｒｓ∩ｒｕ＝空集。Dtr = {(si, hi, ti, yi)， i = 1，…， n}为训练数据集，其中si为一句话，(hi, ti)为si中提到的一个实体对。n为可见关系的个数，yi∈RS表示实体对的关系。类似地，Dts = {(sj, hj, tj, yj)， j = 1，…，Nu}表示测试数据集，其中Nu为不可见关系的个数，yj∈RU表示句子sj中hj和tj的关系。

#### 特征表示

输入一个句子，输出的是他的向量表示。使用分段卷积神经网络模型对输入实例进行编码，再使用两种类型的投影函数，包括design和ConSE得到最终特征表示。



