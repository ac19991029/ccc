# 通过阅读理解提取零样本关系

将一个或多个自然语言问题与每个关系槽关联起来，关系抽取可以简化为回答简单的阅读理解问题。优点：通过神经阅读理解技术学习关系抽取模型；将特定关系的众包问题与远程监督相结合为模型构建庞大数据集；提取只在测试时指定的新关系类型来进行零样本学习。

关系抽取系统用来自非结构化文本语料库的事实填充知识库。当事实(关系)的类型是预定义的，可以使用众包(Liu et al.， 2016)或远程监督(Hoffmann et al.， 2011)来收集例子，并为每个关系类型训练提取模型。然而，这些方法不能提取没有预先指定和在训练中观察到的关系。在本文中，我们提出了一种替代的关系抽取方法，它可以潜在地抽取既没有指定也没有观察到先验的新类型的事实。

这种简化使得构建学习问题的新方法成为可能，零样本场景假设可以访问N个关系类型的标记数据，这些数据通过归纳训练为一个阅读理解模型。但在测试时我们会被问及以前未将的关系类型Rn+1.我们并没有为新关系提供带标签的数据，只是简单列出定义关系槽值的问题，当学习了一个好模型时，我们提取的值应该是正确的。

#### 创新点

零样本设置包括数据和模型方面创新。我们对来自wikidata (Vrandeˇci´c, 2012)的相对大量的关系(120)使用远程监督，这些关系在实践中很容易通过WikiReading数据集收集(Hewlett等人，2016)。另介绍了一种众包方法收集和验证每个关系的问题。因为问题与关系类型（不是实例）配对，所以成本低。

建模的关键挑战是，大多数现有的阅读理解问题公式都假设问题的答案总是出现在给定的文本中。然而，对于关系提取，这个前提不成立，模型需要可靠地确定一个问题何时是不可回答的。我们展示了一种最新的最先进的阅读理解神经方法(Seo等人，2016)，可以直接扩展到可回答性模型，并在我们的新数据集上进行训练。这种建模方法是我们简化的另一个优势:随着机器阅读模型的改进，我们提取关系的能力也应该随着时间的推移而提高。

## Related work

我们对一个特别苛刻的零样本学习场景感兴趣:在训练过程中给定N种关系类型的标记示例，在测试时提取一种新的RN+1关系。关于RN+1，我们仅有的信息是参数化问题。

这种设置不同于当前现有的关系提取技术，Bronstein等人(2015)探索了一个类似的事件触发识别的零射击设置，在这个设置中，RN+1在测试时间由一组触发词指定。他们通过使用无监督方法测量潜在触发器和给定种子集之间的相似性来进行推广。我们关注的是填槽，问题比触发词更适合描述。

开放信息抽取(Open IE) (Banko等人，2007)是一种从文本中抽取事实的无模式方法。虽然开放的IE系统不需要特定于关系的训练数据，但它们经常将不同的短语视为不同的关系。在这项工作中，我们希望提取一个规范槽值，而不依赖于原始文本的表达方式。

通用模式(Riedel et al.， 2013)在一个矩阵中表示开放的IE抽取和知识库事实，其行是实体对，列是关系。冗余模式(每个知识库关系可能与多种自然语言关系重叠)通过矩阵补全技术实现知识库填充。Verga等人(2017)预测原始矩阵中没有观察到的实体对的事实;这相当于用不可见的实体提取可见的关系类型(见章节6.1)。Rockt¨aschel等人(2015)和Demeester等人(2016)使用推理规则从观察到的自然语言关系中预测隐藏的知识库关系。由于训练数据中出现了对每个目标关系的自然语言描述，因此这种设置类似于对同一关系的不同表现形式进行概括(见第6.2节)。此外，与隐含的自然语言问题不同，关于隐性关系的信息是一套显式推理规则。

在通用模式术语中，我们添加了一个新的空列(目标知识库关系)，加上几个新列，每个列都有一个条目(反映句子中的文本关系)。这些列与现有列没有共享实体，这使得矩阵的其余部分不相关。为了从其他列填充空列，我们匹配它们的描述。Toutanova等人(2015)提出了一种类似的方法，分解自然语言关系，并在通用模式设置中计算它们的相似性;然而，他们没有将他们的方法扩展到知识库关系，也没有像我们一样尝试恢复图式外的关系。

## Approach

在关系抽取中，我们考虑填充槽问题，给出一个知识库关系R，一个实体e，一个句子s。我们的，目标是找到一个在s中跨越a的文本集合，其中R（e，a）对于每个a∈a都成立。eg：实体“Steve Jobs”和句子“Steve Jobs was an American businessman, inventor, and industrial designer”例子中，a ={商人，发明家，工业设计师}。当s不包含任何满足R(e， ?)的短语时，空集也是一个有效答案(a =∅)。我们观察到，给定一个表达R(e， ?)的自然语言问题q(例如“史蒂夫·乔布斯是做什么的?”)，解决从s中回答q的阅读理解问题就相当于解决了填槽挑战。

现在的挑战变成了查询:我们将e作为一个变量x，将参数化的查询R(x， ?)(例如，职业(x， ?))作为一个问题模板qx (" What did x do for a living? ")，然后用相关实体实例化这个模板。为每个实体量身定制一个自然语言问题(“史蒂夫·乔布斯是做什么的?”)。这个过程，即模式查询，比查询单个实例的效率高一个数量级，因为注释一个关系类型会自动地注释它的所有实例。

对已存在的关系提取数据集中的N个关系应用模式查询，将其转换为阅读理解数据集。然后，我们使用这个数据集来训练一个阅读理解模型，该模型给出一个句子s和一个问题q，会返回一组跨度为a的文本，这些文本在s范围内回答q

在零样本场景中，我们在测试时得到一个新的关系RN+1(x, y)，这个关系既没有指定，也没有事先观察到。例如，已破译的(x, y)关系，如“图灵和他的同事提出了一种有效破译谜机的方法”，由于领域过于特定，无法存在于公共知识库中。然后，我们将RN+1(x, y)查询为qx(“哪个代码破解了x ?”)或qy(“谁破解了y?”)，并对感兴趣的文档中的每个句子运行我们的阅读理解模型，同时用可能参与到这个关系中的不同实体实例化问题模板1每当模型为给定的问题qe返回一个非空答案a时，它就提取关系RN+1(e, a)。

我们需要为新关系所做的就是以问题的形式定义我们的信息需求我们的方法为那些对在他们的程序中加入关系提取组件感兴趣的应用程序开发人员提供了一个自然语言API;不需要语言知识或预定义的图式。为了实现我们的方法，我们需要两个组件:训练数据和阅读理解模型。我们构造了一个大型的关系抽取数据集，并使用一个高效的众包过程对其进行查询。然后我们采用现有的最先进的阅读理解模型来适应我们的问题表述。

## dataset

我们首先为填充关系槽的任务收集有标记的示例。插槽填充的例子类似于阅读理解的例子，但是包含了一个知识库查询R(e， ?)而不是一个自然语言问题;例如“配偶(Angela Merkel， ?)”，而不是“Angela Merkel嫁给了谁?”我们通过远程监督收集了许多填补空缺的例子，然后将它们的查询转换成自然语言。

使用维基阅读数据集(Hewlett等人，2016)来收集标记槽填充示例。WikiReading是通过将每个Wikidata (Vrandeˇci´c, 2012)的关系R(e, a)与对应实体e的维基百科文章D对齐来收集的，这种关系可以从文章的文本中导出。这个数据集中的每个实例都包含一个关系R、一个实体e、一个文档D和一个答案a。我们使用远程监督来选择每个R(e, a)显示的特定句子。具体来说，我们把D中的第一个句子s包含e和a。然后我们按照R、e和s对实例进行分组，将给定s的R(e， ?)的所有答案合并到一个答案集a中。

在模式级别上的众包查询不是简单的，因为任务必须鼓励员工(a)找出关系的语义(b)在提出问题时具有词汇创造性。因此，我们将众包策略结合在土耳其机械注释的两个阶段:收集和验证。对于每个关系R，我们给注释器提供4个例句，其中每个句子s中的实体e被变量x掩盖了。此外，我们在s中出现的可提取答案a∈a下划线

在验证阶段，我们通过抽样额外的句子和实例实体实例化每个问题模板来衡量问题模板的质量。然后要求注释者从句子中回答问题，或者将其标记为不可回答的;如果注释器的an answer匹配A，那么问题模板是有效的。我们丢弃了在大多数例子中没有正确回答的模板(6/10)

一些最新的QA数据集是通过自然语言表达知识库断言来收集的。Simple QA数据集(Bordes et al.， 2015)是通过注释关于Freebase事实的问题(例如，在图灵(Turing, Princeton)接受教育)创建的，收集了大约10万个自然语言问题，以支持知识图中的QA。Morales等人(2016)使用类似的方法从维基百科信息框中收集问题，生成15000个示例的InfoboxQA数据集。对于识别谓词-论证结构的任务，QASRL (He et al.， 2015)被提出为语义角色的开放模式，其中论证和谓词之间的关系被表示为一个包含谓词(“某人在哪里受教育?”)的自然语言问题，该问题的答案是论证(“普林斯顿”)。作者从3200个句子中收集了大约19,000对问题答案。在这些工作中，成本与实例数量成线性关系，需要对大型数据集进行大量投资。

相比之下，模式查询可以生成大量的数据，而成本只是在关系级标注的一小部分;作为证据，我们能够生成比Simple QA大300倍的数据集。据我们所知，这是第一个通过在模式级别上进行众注来收集问答数据集的健壮方法。

## model

定义：给定一个句子s和一个问题q，我们的算法要么在s中返回一个跨度为5的答案，要么表明没有答案。

最近在SQuAD数据集上研究了自然语言问题的答案范围(Rajpurkar et al.， 2016;Xiong et al.， 2016;Lee等人，2016;王等，2016)。在SQuAD中，每个问题都可以从文本中回答出来，这就是为什么这些模型假设存在一个正确的答案范围。因此，我们以允许它决定答案是否存在的方式修改现有的模型。我们首先给出原始模型的高级描述，然后描述我们的修改

我们从BiDAF模型(Seo et al.， 2016)开始，该模型的输入是两个单词序列:BiDAF使用循环神经网络在s和q中编码上下文信息，同时使用一种注意机制将部分q与s对齐，反之亦然。

BiDAF模型的输出是ystart和yend对于每个可能的起始和结束的置信度得分。我们将这些分数表示为zstart, zend∈RN，其中N是句子s中的单词数。换句话说，zstart 表示答案从句子的第i个位置开始的可能性(越高越有可能);类似地，zend 表示答案在该索引处结束的可能性。假设答案存在，我们可以通过softmax将这些置信分数转换为伪概率分布pstart, pend。因此，上下文的每个i-to-j跨度的概率可以定义为:

![image-20230412124756364](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412124756364.png)

其中pi表示向量pi的第i个元素，即从i开始的答案的概率。

让模型表示没有答案，我们将一个可训练的偏差b连接到两个置信分数向量zstart和zend的末端。~ zstart, zend∈RN+1定义为zstart = [zstart;B]，同样对于z end，其中[;表示按行连接。因此，zstart和zend的最后一个元素分别表示模型对答案没有开始或结束的信心。我们对这些增广向量应用softmax以获得伪概率分布(p, end)。这意味着模型赋给一个空答案的概率是:

![image-20230412125212121](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412125212121.png)

如果P(a =∅)大于最佳span的概率，arg maxi,j≤np (a = si…j)，则模型认为该问题无法从句子中得到答案。从概念上讲，添加偏差可以使模型对原始置信值zstart和zend的绝对值敏感。我们本质上是设置和学习一个阈值b，以决定模型是否对最佳候选答案跨度有足够的信心。

虽然这个阈值为我们提供了一个动态的实例决策，以判断实例是否可回答，但我们也可以设置一个全局置信阈值pmin;如果最佳答案的信心低于这个阈值，我们就推断没有答案。

## experiments

为了理解我们的方法如何很好的推广到不可见的数据，我们为不可见的实体，不可见的问题模板，不可见的关系设计了实验

评估指标每个实例的评估是通过比较标记的答案集与那些预测跨度。精度是真实的正计数除以系统返回非空答案的次数。回忆是真实的正计数除以有答案的实例数。

在我们的实验中，使用GloVe (Pennington et al.， 2014)初始化单词嵌入，并没有对其进行微调。典型的训练集是100万个例子的阶数，3个epoch就足够收敛。所有训练集正负样本比例为1:1，选择正负样本与测试集比例匹配。

除本模型，还比较了其他三个模型

![image-20230412133146715](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412133146715.png)

![image-20230412164609539](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412164609539.png)

![image-20230412164557136](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412164557136.png)

![image-20230412164621024](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230412164621024.png)

## conclusion

我们发现，关系抽取可以简化为一个阅读理解问题，使我们能够将自然语言中动态定义的不可见的关系概括出来。然而，零样本关系抽取的问题还远远没有解决，这对信息抽取和机器阅读社区都提出了有趣的挑战。随着机器阅读研究的进展，我们可能会发现，更多的任务可以从类似的方法中受益。为了支持未来的工作，我们将我们的代码和数据公开