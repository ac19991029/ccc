# 预训练、提示和预测:自然语言处理中的提示方法的系统综述

## Abstract

本文对自然语言处理的一种新范式——“基于提示的学习”进行了综述和梳理。传统的监督学习是训练模型接受输入x并预测输出y为P(y|x)，而基于提示的学习是**基于直接模拟文本概率的语言模型**。为了使用这些模型执行预测任务，**使用模板将原始输入x修改为文本字符串提示x'，其中有一些未填充的槽，然后使用语言模型概率地填充未填充的信息，以获得最终的字符串ˆx，从中可以导出最终的输出y**。

这个框架的强大和吸引人的原因有很多:**它允许对语言模型进行大量的原始文本的预训练，通过定义一个新的提示函数，该模型能够执行少样本甚至零样本学习，以适应具有很少或没有标记数据的新场景。**

在本文中，我们介绍了这个有前途的范例的基础，描述了一组统一的数学符号，它可以涵盖各种各样的现有工作，并沿着几个维度组织现有工作，例如，选择预先训练的模型、提示符和调优策略。为了让有兴趣的初学者更容易理解这个领域，我们不仅对现有的作品进行了系统的回顾，并对基于提示的概念进行了高度结构化的分类，而且还发布了其他资源，例如一个网站NLPedia-Pretrain，包括不断更新的调查和论文列表。

## Two Sea Changes in NLP

完全监督学习，即**任务特定模型仅在目标任务的输入-输出示例数据集上训练**，长期以来一直在许多机器学习任务中扮演中心角色(Kotsiantis等人，2007)，自然语言处理(NLP)也不例外。

由于这种完全监督的数据集**永远不足以学习高质量的模型，早期的NLP模型严重依赖于特征工程**,其中NLP研究人员或工程师使用他们的领域知识**从原始数据中定义和提取显著特征**，并提供**具有适当归纳偏差的模型**，以从这些有限的数据中学习。

随着NLP的神经网络模型的出现，显著特征是与模型本身的训练一起学习的(Collobert et al.， 2011;Bengio et al.， 2013)，因此重点转移到建筑工程，在建筑工程中，归纳偏向是通过设计一个适合的网络结构，有利于学习这些特征

然而，从2017-2019年开始，NLP模型的学习发生了翻天覆地的变化，这种完全监督的范式正在发挥越来越小的作用。具体来说，**标准转移到训练前和微调范式**

在这种范式中，具有固定架构的模型被预先训练为语言模型(LM)，**预测观察到的文本数据的概率**。

因为训练lm所需的原始文本数据非常丰富，所以可以在大型数据集上训练这些lm，在学习它所建模的语言的健壮的通用特性的过程中。通过引入额外的参数并使用任务特定的目标函数对其进行微调，将上述预先训练的LM应用于不同的下游任务。在这一范式中，重点主要转向目标工程，设计在培训前和微调阶段使用的培训目标。

## A Formal Description of Prompting

### Supervised Learning in NLP

在传统的NLP监督学习系统中，我们取一个输入x，通常是文本，然后根据一个模型P(y|x;θ)。Y可以是标签、文本或其他各种输出。为了学习该模型的参数θ，我们使用一个包含对输入和输出的数据集，并训练一个模型来预测该条件概率。

### Prompting Basics

监督学习的主要问题是，为了训练一个模型P(y|x;θ)，对于任务来说，**有必要有监督数据，而对于很多任务来说，监督数据是无法大量找到的。**

基于即时学习的NLP方法试图绕过这个问题，取而代之的是**学习一个模拟概率P(x;θ)，并使用这种概率来预测y，减少或消除对大型监督数据集的需求。**具体来说，基本提示通过三个步骤预测出得分最高的ˆy。

#### Prompt Addition

在此步骤中，将应用提示函数fprompt(·)将输入文本x修改为提示符x'= fprompt(x)

1. 应用一个模板，它是一个文本字符串，具有两个插槽:一个输入插槽[X]用于输入X，一个回答插槽[Z]用于中间生成的回答文本Z，稍后将映射到y。
2. 用输入文本X填充槽[X]。

在情感分析的例子中，x =“我喜欢这部电影。，模板可能采取这样的形式:“[X]总的来说，这是一部[Z]电影。”然后，x'变成“我喜欢这部电影。总的来说，这是一部[Z]电影。

上面的提示符将有一个空槽来填充z，要么在提示符中间，要么在提示符末尾。在下面的文本中，我们将第一种类型的提示符称为**完形提示符，其中有一个槽在文本中间填充**，第二种类型的**提示符将输入文本完全放在z之前，作为前缀提示符。**在很多情况下，这些模板词不一定由自然语言符号组成;它们可以是**虚拟的单词**(例如用数字id表示)，之后嵌入到一个连续的空间中，有些提示方法甚至直接生成连续的向量。 [X]槽数和[Z]槽数可**根据手头任务的需要灵活调整**

#### Answer Search

我们搜索得分最高的文本zˆ，它使LM的得分最大化。首先，我们将Z定义为**z**的一组允许值。Z可以是生成任务中语言的整个范围，也可以是分类任务中语言中单词的一个小子集，例如定义Z = {" excellent "， " good "， " OK "， " bad "， " horrible "}来表示Y ={++， +，~，-，-}中的每个类。

我们定义一个函数ffill(x'，z)，它**用可能的答案z填充提示符x'中的位置[z]**。我们将调用经过此过程的任何提示符作为填充的提示符。特别是，如果提示符中填充了**真实的答案，我们将把它称为已回答的提示符**最后，我们使用一个预先训练的LM P(·;θ)

![image-20230913151546092](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230913151546092.png)

这个搜索函数可以是**搜索得分最高的输出的argmax搜索**，也可以是根据**LM的概率分布随机生成输出的采样**。

#### Answer Mapping

我们想从得分最高的答案ˆz到得分最高的输出ˆy。在某些情况下，这是微不足道的，其中答案本身就是输出(如在翻译等语言生成任务中)，但也有其他情况，**多个答案可能导致相同的输出**。例如，可以使用多个不同的情感词汇(例如“excellent”，“fabulous”，“wonderful”)来表示单个类(例如“++”)，在这种情况下，必须在搜索的答案和输出值之间有一个映射。

## Pre-trained Language Models

我们对各种预训练的lm提出了一个系统的观点，它(i)**以更系统的方式将它们沿着不同的轴组织起来**，(ii)**特别侧重于提示方法突出的方面。**

### Training Objectives

预先训练的LM的主要训练目标几乎总是**由某种预测文本x的概率的目标**组成。

#### Standard Language Model (SLM)

训练模型从训练语料库中优化文本的概率P(x) (Radford等人，2019)。在这些情况下，通常以自回归的方式预测文本，每次预测序列中的标记。这通常从左到右完成(如下所示)，但也可以按其他顺序完成。

对于标准LM目标的一种流行的替代方法是**去噪目标**，它将一些噪声函数x ~ = fnoise(x)应用于输入句子,然后给定这个噪声文本P(x| ~ x)，尝试预测原始的输入句子。这些目标有两个共同点:

1. 损坏的文本重建(CTR).这些目标通过计算输入语句噪声部分的损失，将处理后的文本恢复到未损坏的状态。
2. 全文重建(FTR).这些目标通过计算整个输入文本的损失来重建文本，不管它是否被噪声处理过

训练前的LMs的主要训练目标**在决定其对特定提示任务的适用性方面起着重要作用**。例如，从左到右的自回归LMs可能特别适合于**前缀提示**，而重构目标可能更适合于**完形填空提示**。此外，使用标准LM和FTR目标训练的模型可能更适合于**有关文本生成的任务**，而其他任务，如分类，则可以使用使用这些目标训练的模型来制定。

### Noising Functions

在基于重构的训练目标中，用于获取噪声文本的特定类型的损坏(corruption)会**影响学习算法的效力**。此外，先验知识可以通过控制噪声的类型来整合，例如，噪声可以集中在一个句子的实体上，这让我们学习一个预先训练的模型，对实体具有特别高的预测性能。

#### Masking

文本将被屏蔽在不同的级别，用特殊的令牌(如[MASK])替换一个令牌或多个令牌跨度。值得注意的是，掩蔽可以是随机的，也可以是专门设计来引入先验知识的，例如上面提到的掩蔽实体的例子，以鼓励模型能够很好地预测实体。

#### Replacement

替换类似于屏蔽，除了令牌或多令牌的跨度不是用[MASK]替换，而是用另一个令牌或一条信息

#### Deletion

令牌或多个令牌跨度将从文本中删除，而不需要添加[MASK]或任何其他令牌。这种操作通常与FTR损失一起使用。

#### Permutation

文本首先被划分为不同的跨度(标记、子句子跨度或句子)，然后这些跨度被排列成新的文本。

### Directionality of Representations

在理解预训练的lm和它们之间的区别时，应该考虑的最后一个重要因素是表征计算的方向性。一般来说，有两种广泛使用的方法来计算这种表示:

#### Left-to-Right

每个单词的表示是基于单词本身和句子中所有之前的单词来计算的。

例如，如果我们有一个句子“This is a good movie”，那么“good”这个词的表示就会根据之前的单词来计算。这种分解在计算标准LM物镜或计算FTR物镜输出端时特别广泛地使用

#### Bidirectional(双向)

每个单词的表示是基于句子中的所有单词计算的，包括当前单词左边的单词。在上面的例子中，“good”会受到句子中所有单词的影响，甚至是后面的“movie”。

### Typical Pre-training Methods

![image-20230913171333739](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230913171333739.png)

#### Left-to-Right Language Model

从左到右的LM (L2R LM)，即各种自回归LM，预测即将到来的单词，或为x = x1，···，xn的单词序列分配概率P(x).概率通常用链式法则从左到右分解:P(x) = P(x1) ×···P(xn|x1···xn−1)。

#### Masked Language Models

虽然自回归语言模型为文本概率建模提供了一个强大的工具，但它们也有缺点，比如需要从左到右计算表示。当焦点转移到为下游任务(如分类)生成最佳表示时，许多其他选项就成为可能，而且通常更可取。掩蔽语言模型(MLM;Devlin等人(2019))，其目标是根据包围的上下文预测隐藏的文本片段。例如，P(xi|x1，…， xi−1,xi+1，…， xn)表示单词xi在给定上下文的情况下出现的概率。

### Prefix and Encoder-Decoder

对于翻译和摘要等条件文本生成任务，输入文本x = x1，···，xn是给定的，目标是生成目标文本y，我们需要一个预先训练的模型，既能对输入文本进行编码，又能生成输出文本。

有两种流行的体系结构，它们共享一个线程**(1)，使用带有完全连接掩码的编码器首先对源x进行编码，然后(2)自回归地(从左到右)对目标y进行解码。**

#### Prefix Language Model

前缀LM是一个从左到右的LM，以前缀序列x为条件对y进行解码，该序列由相同的模型参数编码，但具有完全连接的掩码。值得注意的是，为了鼓励前缀LM更好地学习输入的表示，通常**在x上应用一个损坏的文本重构目标，在y上应用一个标准条件语言建模目标。**

#### Encoder-decoder

该编码器-解码器模型使用**一个从左到右的LM来解码一个单独的编码器条件下的文本x与一个完全连接的掩码**;编码器和解码器的参数不共享。与前缀LM类似，可以对输入x施加不同类型的噪声。

## Prompt Engineering

提示工程是创建一个提示函数fprompt(x)的过程，该函数能在下游任务上产生最有效的性能。

我们必须首先考虑**提示的形状**，然后决定是采用**手动方式还是自动方式**来创建所需形状的提示，如下所示。

### Prompt Shape

有两种主要类型的提示语:**完形填空提示语**(Petroni等人，2019;Cui等人，2021)，填充文本字符串的空白，以及**前缀提示符**(Li和Liang, 2021;Lester等人，2021)，它继续一个字符串前缀。选择哪一个取决于任务和用于解决任务的模型。

对于与生成有关的任务，或者**使用标准的自回归LM来解决**的任务，**前缀提示**往往更有益，因为它们与模型的从左到右的性质很好地吻合。对于使**用蒙面lm解决**的任务，**完形填空提示**非常适合，因为它们与训练前任务的形式非常匹配。**全文重构模型更加通用，可以使用完形填空或前缀提示符**。最后，对于一些涉及多个输入的任务，如文本对分类，提示模板必须包含两个输入的空格，[X1]和[X2]，或更多。

### Manual Template Engineering

创建提示的最自然的方式是**基于人的自省手动创建直观的模板**。例如，开创性的LAMA数据集(Petroni et al.， 2019)提供了**手工创建的完形模板**来探索lm中的知识。Brown等人(2020)创建了**手工制作的前缀提示符**，以处理各种各样的任务，包括回答问题、翻译和用于常识推理的探测任务。Schick和Sch¨utze (2020, 2021a,b)在文本分类和条件文本生成任务的少样本学习设置中使用预定义模板。

### Automated Template Learning

手工制作模板的策略是直观的，并允许以一定程度的准确性解决各种任务，但这种方法也存在几个问题:(1)创建和试验这些提示是一门需要时间和经验的艺术，特别是对于一些复杂的任务，如语义解析(Shin等人，2021);(2)即使是经验丰富的提示设计师也可能无法手动发现最优提示

**自动诱导的提示可以进一步分为离散提示(提示是一个实际的文本字符串)和连续提示(提示是直接在底层LM的嵌入空间中描述的)。**

另一个正交设计需要考虑的问题是，提示函数fprompt(x)是**静态的**(对每个输入使用相同的提示模板)，还是**动态的**(为每个输入生成一个定制模板)。

#### Discrete Prompts

离散提示(又称硬提示)，**自动搜索离散空间中描述的模板**，通常对应于自然语言短语。下面我们将详细介绍几种已提出的方法:

1. Prompt Mining:Jiang等人(2020c)的MINE方法是一种基于挖掘的方法，可以**自动找到给定一组训练输入x和输出y的模板**。该方法从大型文本语料库(如Wikipedia)中提取包含x和y的字符串，并找到输入和输出之间的中间单词或依赖路径。频繁的中间词或依赖路径可以作为模板，如“[X]中间词[Z]”。
2. Prompt Paraphrasing:基于释义的方法采用现有的**种子提示(**例如手工构建或挖掘)，并将其解释为一组其他候选提示，然后选择在目标任务中达到最高训练精度的提示。
3. Gradient-based Search:Wallace等人(2019a)在实际令牌上应用了**基于梯度的搜索**，以找到**能够触发底层预训练LM以生成所需目标预测的短序列**。这种搜索是以**迭代**的方式完成的，在提示符中逐行执行标记。基于这种方法，Shin等人(2020)使用下游应用程序训练样本自动搜索模板令牌，并在提示场景中展示了强大的性能。
4. Prompt Generation:将**提示的生成视为文本生成任务**，并使用标准的自然语言生成模型来执行该任务。Gao等人(2021)**将seq2seq预训练的模型T5引入到模板搜索过程中**。由于T5已经被预先训练完成了填入missing span的任务，所以他们使用**T5来生成模板令牌**，方法是(1)指定**在template中插入模板令牌的位置**(2)**为T5提供训练样本来解码模板令牌**。Ben-David等人(2021)提出了一种领域自适应算法，训练T5生成唯一的领域相关特征(DRFs;表示领域信息的一组关键字)。然后这些drf可以与输入连接起来形成一个模板，并被下游任务进一步使用。
5. Prompt Scoring:Davison等人(2019)研究了知识库完成的任务，并使用LMs为输入(头-关系-尾三元组)设计了一个模板。他们**首先**手工制作一组模板作为潜在的候选者，**然后**填充输入和回答插槽以形成一个填充的提示。**然后**，他们使用单向LM来给那些填满的提示打分，选择LM概率最高的提示。这将为每个单独的输入生成自定义模板。

#### Continuous Prompts

提示构造的目的是找到一种方法，使LM能够有效地执行任务，而不是供人类使用，因此没有必要将提示限制为人类可解释的自然语言。

还有一些方法可以检查连续提示(也称为软提示)，这些提示可以直接在模型的嵌入空间中执行提示。具体来说，连续提示**消除了两个约束**:(1)放松了模板词嵌入为自然语言(如英语)词嵌入的约束。(2)消除了模板是由预训练LM的参数参数化的限制。

Prefix Tuning:前缀调优**将一系列连续的特定于任务的向量前置到输入**，同时保持LM参数不变。

数学上，这包括给定一个可训练的前缀矩阵Mφ和一个固定的θ参数化的预训练LM的对数似然目标的优化。

![image-20230914140717369](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230914140717369.png)

h<i = [h(1) <i;···;h(n) <i]为所有神经网络层在时间步长i处的串联，如果对应的时间步长在前缀范围内(hi为Mφ[i])，则直接从Mφ复制，否则使用预训练的LM计算。

Tuning Initialized with Discrete Prompts:使用已经使用离散提示符搜索方法创建或发现的提示符初始化连续提示符的搜索。

Hard-Soft Prompt Hybrid Tuning:没有使用纯可学习的提示模板，而是将一些可调的嵌入插入到硬提示模板中。

## Answer Engineering

与为提示方法设计适当输入的提示工程不同，回答工程的目标是**搜索答案空间Z和原始输出Y的映射**，从而得到一个有效的预测模型。

### Answer Shape

答案的形状表明了答案的粒度。一些常见的选择包括

1. 记号:预先训练的LM词汇表中的一个记号，或词汇表的一个子集。
2. 跨度:一个短的多令牌跨度。这些通常与完形填空提示一起使用。
3. 句子:一个句子或文件。这些通常与前缀提示一起使用。

在实践中，如何选择可接受答案的形式取决于我们想要执行的任务。**符号或文本跨度答案空间**被广泛应用于分类任务中(如情感分类;Yin等人(2019))，以及其他任务，如关系提取(Petroni等人，2019)或命名实体识别(Cui等人，2021)。**较长的短语或句子答案**通常用于语言生成任务(Radford et al.， 2019)，但也用于其他任务，如多项选择问题的回答(其中多个短语的得分相互比较;Khashabi等人(2020))。

### Answer Space Design Methods

如果答案没有用作最终输出，如何设计适当的答案空间Z，以及到输出空间Y的映射?

#### Manual Design

手工设计中，潜在答案Z的空间及其到Y的映射是由感兴趣的系统或基准设计人员手工制作的。

1. Unconstrained Spaces:答案空间Z是所有**令牌**(Petroni等人，2019)、**定长跨度**(Jiang等人，2020a)或**令牌序列**(Radford等人，2019)的空间。在这些情况下，最常见的是**使用单位映射将答案z直接映射到最终输出y**。
2. Constrained Spaces:通常用于标签空间有限的任务，如**文本分类或实体识别，或多选题回答**。
3. 对于多项选择题的回答，通常使用LM来计算多个选择中输出的概率

#### Discrete Answer Search

1. Answer Paraphrasing:从一个初始的答案空间Z'开始，然后使用释义来扩展这个答案空间，以扩大其覆盖范围.给定一对答案并输出{z'，y}，我们定义一个函数来生成一组答案(z')。最终输出的概率定义为这个释义集P(y|x) =Σz∈para(z')P(z|x)中所有答案的边际概率。
2. Prune-then-Search（剪枝搜索）：首先生成几个可信答案Z’的初始剪枝答案空间，然后算法进一步搜索这个剪枝空间以选择最终的答案集。
3. Label Decomposition（标签分解）：Chen等(2021b)在进行关系提取时，**自动将每个关系标签分解为其组成词，并将其作为答案**。答案跨度的概率将计算为每个令牌的概率之和。

#### Continuous Answer Search

很少有作品探索使用软答案令牌的可能性，可以通过**梯度下降**进行优化。Hambardzumyan等人(2021)**为每个类标签分配一个虚拟令牌**，并优化每个类的令牌嵌入以及提示令牌嵌入

## Multi-Prompt Learning

使用多个提示可以进一步提高提示方法的有效性，我们将这些方法称为多提示学习方法。

### Prompt Ensembling

提示集成是在推理时为输入使用**多个未回答的提示进行预测的过程**。多个提示可以是离散提示，也可以是连续提示

即时集成可以(1)利用不同提示符的**互补优势**，(2)**减轻**即时工程的成本，因为选择一个表现最好的提示符是一项挑战，(3)**稳定下游任务的性能**。

Uniform averaging：使用多个提示时，组合预测的最直观的方法是**对不同提示的概率取平均值**。具体来说，这表示P(z|x):= 1/KΣK i P(z|fprompt,i(x))其中fprompt,i(·)是提示符集合中的第i个提示符。

Weighted averaging：在提示集合中使用**加权平均值**，其中**每个提示都与一个权重相关联**。权重通常是根据提示性能预先指定的，或者使用训练集进行优化。

Majority voting：对于分类任务，**多数投票**也可以用来组合不同提示符的结果

Knowledge distillation：深度学习模型的集合通常可以提高性能，而这种优越的性能可以通过知识提炼被提炼成一个单一的模型

Prompt ensembling for text generation：执行集成的一种简单方法是使用标准方法，根据答案序列P(zt|x, z<t)中下一个单词的集成概率生成输出:= 1/KΣK i P(zt|fprompt,i(x)， z<t)。

### Prompt Augmentation

提示增强，有时也称为演示学习(Gao et al.， 2021)，提供了一些额外的回答提示，可以用来**演示LM应该如何为输入x实例化的实际提示提供答案**。

具有以下几个方面的挑战性:(1)样本选择:如何选择最有效的例子?(2)样本排序:如何在提示下对所选的样本进行排序?

#### Sample Selection

在这个少样本场景中使用的例子的选择可能会导致非常不同的性能，从对某些任务近乎最先进的准确性到近乎随机猜测，为了解决这一问题，Gao等人(2021);Liu等人(2021a)利用**句子嵌入来抽取**与嵌入空间相近的样本。

#### Sample Ordering

Lu等人(2021)发现提供给模型的回答**提示的顺序**对模型性能起着重要作用，并提出了**基于熵**的方法来对不同的候选排列进行评分。

### Prompt Composition

对于那些可组合的任务(它们可以基于更基本的子任务组合)，我们还可以**执行提示组合**，使用多个子提示符，每个子提示符对应一个子任务，然后根据这些子提示符定义一个复合提示符。

### Prompt Decomposition

对于需要**对一个样本进行多个预测的任务**(例如，序列标记)，直接定义关于整个输入文本x的整体提示是具有挑战性的。

解决这一问题的一种直观方法是将整体提示分解成不同的子提示，然后分别回答每个子提示。

## Training Strategies for Prompting Methods

### Training Settings

提示方法可以在没有对下游任务的LM进行任何显式训练的情况下使用，而只是使用一个经过训练的LM来预测文本P(x)的概率，并将其应用于为指定任务而定义的完形填空或前缀提示。这传统上被称为**零样本设置**，因为对于感兴趣的任务没有训练数据。

然而，也有一些方法使用训练数据来训练模型，并与提示方法相配合。这包括**全数据学习**(使用相当多的训练示例来训练模型)和**少样本学习**(使用非常少的示例来训练模型)。提示方法在后一种情况下特别有用，因为通常没有足够的训练例子来完全指定期望的行为，因此使用提示将模型推向正确的方向是特别有效的。

### Parameter Update Methods

在基于提示的下游任务学习中，通常有两类参数，即(1**)预训练模型参数**和(2)**提示参数参数**。

> 根据(i)**底层LM的参数是否被调优**，(ii)**是否有额外的提示相关参数**，(iii)**如果有**额外的提示相关参数，**是否对这些参数进行调优**，我们总结出五种调优策略

![image-20230914152504689](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230914152504689.png)

#### Promptless Fine-tuning

我们将没有提示的训练前和微调称为无提示微调。在这个策略中，给定一个任务的数据集，**所有(或部分**(Howard and Ruder, 2018;Peters等人，2019))**的预训练LM的参数将通过下游训练样本诱导的梯度进行更新**

优点:简单，无需即时设计。调整所有LM参数允许模型适应更大的训练数据集。

缺点:lm可能会过拟合或不能在较小的数据集上稳定地学习。

#### Tuning-free Prompting

无调优提示直接生成答案，而不改变仅基于提示的预训练lm的参数，无调优提示和提示增强的组合也被称为上下文学习

优点:效率高，没有参数更新过程。没有灾难性的遗忘，因为LM参数保持不变。适用于零样本设置。

缺点:由于提示符是提供任务规范的唯一方法，因此需要大量的工程来实现高精度。特别是在上下文学习设置中，在测试时提供许多回答的提示可能会很慢，因此不能轻易地使用大型训练数据集。

#### Fixed-LM Prompt Tuning

在预训练模型的参数之外增加提示相关参数的情况下，固定LM提示调优仅**利用下游训练样本的监督信号更新提示的参数**，而保持整个预训练LM不变。典型的例子是**前缀调优**

优点:与无调优提示类似，它可以在LMs中保留知识，适用于少样本场景。通常精度优于无调优提示。

缺点:不适用于零样本场景。虽然在少样本场景中有效，但在大数据环境中表示能力是有限的。通过选择超参数或种子提示进行快速工程是必要的。

#### Fixed-prompt LM Tuning

固定提示的LM调优对LM的参数进行调优，就像在标准的预训练和微调范例中一样，但是还使用带有固定参数的提示来指定模型行为。这可能会带来改进，特别是在少样本场景中。

最自然的方法是提供一个离散的文本模板，应用于每个训练和测试示例。

优点:提示或回答工程更完整地指定任务，允许更有效的学习，特别是在少样本的情况下。

缺点:提示或回答工程仍然需要，尽管可能不如没有提示那么多。在一个下游任务上进行微调的lm可能在另一个任务上并不有效。

#### Prompt+LM Tuning

存在与提示相关的参数，这些参数可以与预训练模型的全部或部分参数一起进行微调。

优点:这是最具表现力的方法，可能适合于高数据设置。

缺点:需要培训和存储模型的所有参数。可能对小数据集过拟合。

## Applications

### Knowledge Probing

#### Factual Probing

事实探测(又称事实检索)是最早应用提示方法的场景之一。

探索这一任务的动机是**量化多少事实知识的预先训练的LM的内部表征承受**。在该任务中，预训练模型的参数通常是固定的，通过**将原始输入转换为完形提示符来检索知识**，该提示符可以手工制作，也可以自动发现。

相关数据集包括LAMA (Petroni等人，2019)和X-FACTR (Jiang等人，2020a)。

#### Linguistic Probing

除了事实知识外，大规模的前训练也允许LMs处理语言现象，如类比(Brown et al.， 2020)、否定(Ettinger, 2020)、语义角色敏感性(Ettinger, 2020)、语义相似度(Sun et al.， 2021)、不能理解(Sun et al.， 2021)和罕见词理解(Schick and Sch¨utze, 2020)。上述知识也可以通过以自然语言句子的形式呈现语言探究任务而得到，这些任务由LM来完成

### Classification-based Tasks

对基于分类的任务进行提示的关键是**将其重新定义为适当的提示**。

#### Text Classification 

对于文本分类任务，之前的大多数工作都使用完形提示符和提示工程(Gao等人，2021;Hambardzumyan等人，2021年;Lester等人，2021年)和回答工程(Schick and Sch¨utze, 2021a;Schick等人，2020年;Gao等人，2021年)进行了广泛的探索。大多数现有的著作都探讨了在少样本背景下，采用“固定提示LM调优”策略(参见§7.2.4)提示学习对文本分类的效果。

#### Natural Language Inference (NLI)

NLI的目标是**预测两个给定句子之间的关系**(如蕴涵关系)。与文本分类任务类似，自然语言推理任务通常使用完形填空提示符

对于提示工程，研究者主要关注的是在少样本学习设置下的模板搜索，而答案空间Z通常是从词汇表中手动预选。

### Information Extraction

#### Relation Extraction

关系抽取是一项预测句子中两个实体之间关系的任务。

#### Semantic Parsing

语义分析的任务是在给定自然语言输入的情况下生成结构化的语义表示。

#### Named Entity Recognition

命名实体识别(NER)是在给定的句子中识别命名实体(如人名、位置)的任务

### “Reasoning” in NLP

#### Commonsense Reasoning（常识推理）

#### Mathematical Reasoning

数学推理是解决数学问题的能力，例如算术加法，函数求值。

### Question Answering

问题回答(QA)的目的是回答给定的输入问题，通常基于上下文文档。

通常，使用不同的建模框架来处理这些不同的格式。使用lm解决QA问题(可能使用提示方法)的一个好处是，可以在同一个框架中解决不同格式的QA任务。

### Text Generation

文本生成是一系列涉及生成文本的任务，通常以其他信息为条件。通过使用前缀提示和自回归的预训练lm，提示方法可以很容易地应用于这些任务。

### Automatic Evaluation of Text Generation

uan等人(2021b)证明了提示学习可以用于生成文本的自动评估。具体来说，他们将生成文本的评估概念化为一个文本生成问题，使用预先训练的序列对序列建模，然后使用前缀提示，使评估任务更接近于预先训练的任务。

### Multi-modal Learning

TsimMeta-Applicationspoukelli等人(2021)将提示学习的应用从基于文本的NLP转向多模态设置(视觉和语言)。

### Meta-Applications

#### Domain Adaptation

领域适应是将一个模型从一个领域(如新闻文本)调整到另一个领域(如社交媒体文本)的实践。

#### Debiasing

Schick等人(2021)发现LMs可以根据有偏或去偏指令进行自诊断和自去偏。

#### Dataset Construction

Schick和Sch¨utze(2021)提议使用经过训练的lm生成给定特定指令的数据集。例如，假设我们有一个未标记的数据集，其中每个样本都是一个句子。如果我们想要构建一个包含语义相似的句子对的数据集，那么我们可以为每个输入的句子使用以下模板:“写两个意思相同的句子。[X][Z]”，并尝试生成一个与输入的句子具有相同意思的句子。

## Prompt-relevant Topics

### Ensemble Learning

集成学习(Ting and Witten, 1997;Zhou等人，2002)是一种旨在通过利用多个系统的互补性来提高任务性能的技术。通常，集成中使用的不同系统来自于不同的架构、训练策略、数据顺序和/或随机初始化的选择。

### Few-shot Learning

少样本学习的目的是在数据稀缺的情况下，用很少的训练样本来学习机器学习系统。实现少样本学习的方法有很多种，包括模型不可知者元学习(Finn et al.， 2017b)(学习特征可快速适应新任务)，嵌入学习(Bertinetto et al.， 2016)(将每个样本嵌入到一个低维空间中，其中相似样本之间距离较近)，基于记忆的学习(Kaiser et al.， 2017)(用来自记忆的内容的加权平均表示每个样本)等(Wang et al.， 2020)。

提示增强可以被看作是实现少样本学习的另一种方式(又称基于原始输入的少样本学习(Kumar和Talukdar, 2021))。与之前的方法相比，提示增强直接将多个标记的样本前置到当前处理的样本中，无需任何参数调整即可从预训练的lm中引出知识。

### Larger-context Learning

大语境学习旨在通过增加额外的语境信息(例如从训练集(Cao et al.， 2018)或外部数据源(Guu et al.， 2020)检索输入来提高系统的性能。提示增强可以看作是将相关的标注样本加入到输入中，但在大语境学习中，引入的上下文不一定是标注数据。

### Query Reformulation

查询重构(Mathieu和Sabatier, 1986;Daum´e III和Brill, 2004)通常用于**信息检索**(Nogueira和Cho, 2017)和**问题回答任务**(Buck等人，2017;Vakulenko等人，2020年)，其目的是通过使用相关查询词扩展输入查询(Hassan, 2013年)或生成意译，来引出更多相关文本(文档或答案)。

传统的查询重组问题中的知识库通常是一个搜索引擎(Nogueira和Cho, 2017)，或QA系统(Buck等人，2017)。

相比之下，对于基于提示的学习，我们通常将这个知识库定义为LM，并需要找到适当的查询来从它中引出适当的答案。提示学习中的输入重组改变了任务的形式。

### QA-based Task Formulation

基于qa的任务提法旨在将不同的自然语言处理任务概念化为一个问答问题。

### Controlled Generation

控制生成的目的是**将输入文本之外的各种类型的指导纳入生成模型**(Yu等人，2020)。具体来说，制导信号可以是样式标记(Sennrich等人，2016b;Fan等人，2018)、长度规范(Kikuchi等人，2016)、域标签(Chu等人，2017)或用于控制生成文本的任何其他信息片段。也可以是关键词(Saito等人，2020)、关系三元组(Zhu等人，2020)或甚至是突出显示的短语或句子(Grangier和Auli, 2018;Liu等人，2021c)来规划生成文本的内容。

### Supervised Attention

从长文本序列等对象中提取有用信息时，**知道注意重要信息**是关键步骤(Liu et al.， 2016;Sood等人，2020年)，图像(Sugano和Bulling, 2016年;Zhang等人，2020b)，或知识库(Yu等人，2020;Dou等人，2021))。

监督式注意(Liu et al.， 2017b)旨在基于完全数据驱动的注意可能对某些工件过拟合这一事实，对模型的注意提供明确的监督

提示学习和监督注意分享的想法，都旨在提取突出的信息与一些线索，这需要单独提供

### Data Augmentation

数据增强是一种通过修改现有数据来增加可用于培训的数据量的技术

## Challenges

### Prompt Design

#### Tasks beyond Classification and Generation

现有的关于基于提示的学习的大多数工作要么围绕文本分类，要么围绕基于生成的任务。对于信息提取和文本分析任务的应用程序讨论得较少，这主要是因为**提示符的设计不够直接**。

#### Prompting with Structured Information

在许多NLP任务中，输入被灌输了一些不同的结构，如树、图、表或关系结构。如何在快速或回答工程中最好地表达这些结构是一个主要的挑战。

#### Entanglement of Template and Answer模板和答案的纠缠

模型的性能将取决于所使用的模板和所考虑的答案。如何同时搜索或学习模板和答案的最佳组合仍然是一个具有挑战性的问题。

### Answer Engineering

#### Many-class and Long-answer Classification Tasks多类和长答案分类任务

对于基于分类的任务，答案工程面临**两个主要挑战**:(a)当类过多时，如何选择合适的答案空间成为一个困难的组合优化问题。(b)在使用多令牌答案时，尽管已经提出了一些多令牌解码方法，但如何使用lm最佳地解码多个令牌仍然未知

#### Multiple Answers for Generation Tasks

对于文本生成任务，合格的答案在语义上是等价的，但在语法上是不同的。到目前为止，几乎所有的作品都使用提示学习来生成文本，仅仅依靠一个答案

### Selection of Tuning Strategy

有相当多的方法可以调优提示、lm或两者的参数。然而，鉴于这一研究领域的初期阶段，我们仍然缺乏对这些方法之间的权衡的系统理解。

### Multiple Prompt Learning

#### Prompt Ensembling

在提示集成方法中，当我们考虑更多的提示时，空间和时间复杂度会增加。如何从不同的提示中提取知识仍然有待探索

Schick和Sch¨utze (2020,2021a,b)使用一个集成模型对一个大数据集进行注释，从多个提示中提取知识。此外，如何选择适合整体效果的提示也没有得到充分的探讨。

#### Prompt Composition and **Decomposition提示符组成与分解**

提示符的组成和分解都是通过引入多个子提示符来分解复杂任务输入的难度。在实践中，如何在两者之间做出正确的选择是至关重要的一步。

#### Prompt Augmentation

现有的提示增强方法受到输入长度的限制，即输入时提供过多的演示是不可行的。因此，如何选择有信息的演示，并以适当的顺序排列是一个有趣但具有挑战性的问题

#### Prompt Sharing

上述所有考虑都是指在单个任务、领域或语言中的提示符应用。我们也可以考虑即时共享，即将提示学习应用于多个任务、领域或语言。

可能出现的一些关键问题包括如何为不同的任务设计单个提示符，以及如何调节它们之间的交互。

### Selection of Pre-trained Models

由于有大量经过培训的lm可供选择(见§3)，如何选择他们以更好地利用基于即时学习是一个有趣而又困难的问题。

### Theoretical and Empirical Analysis of Prompting

尽管他们在很多情况下都取得了成功，但是对于快速学习的理论分析和保障却很少。

### Transferability of Prompts