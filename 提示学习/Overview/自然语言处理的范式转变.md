# 自然语言处理的范式转变

## Abstract

在深度学习的时代，大多数NLP任务的建模已经融合为几种主流范式。例如，我们通常采用**序列标记范式**解决POS-tagging、NER、Chunking等一系列任务，采用**分类范式解决情感分析**等任务。随着语言模型的快速发展，近年来出现了**范式转移**的趋势，即通过**重新构造一个NLP任务来解决另一个NLP任务**。范式转换在许多任务上取得了巨大的成功，成为提高模型性能的有效途径。此外，其中一些范例显示出了统一大量NLP任务的巨大潜力，使构建一个模型来处理不同的任务成为可能。在本文中，我们回顾了近年来这种范式转移现象，并着重指出了几种有潜力解决不同的NLP任务的范式。

## Introduction

范式**是对一类任务建模的一般框架**。例如，序列标记是命名实体识别的主流范式。不同的范例通常需要不同的输入和输出，因此高度依赖于任务的注释。在过去的几年里，大多数NLP任务的建模已经收敛到几个主流范式，如本文所总结的:Class、Matching、SeqLab、MRC、**Seq2Seq**、Seq2ASeq和**(M)LM**。

MRC范式和Seq2Seq范式也可以在NER任务上实现最先进的性能(Li et al.， 2020;Yan等人，2021b)，这在之前的序列标记(SeqLab)范式中被形式化。

这些方法通常首**先将数据集的形式转换为新范式所需的形式**，然后使用新范式下的模型来解决任务。

本文试图对范式转移这一研究领域的最新进展和趋势进行综述

## Paradigms in NLP

### Paradigms, Tasks, and Models

一个任务对应一个数据集D = {Xi, Yi}N i=1。范式是一种通用的建模框架，用于**将某些数据集(或任务)适应于特定的格式(即X和Y的数据结构)**。

### The Seven Paradigms in NLP

我们主要考虑在NLP任务中广泛使用的七个范式，即Class、Matching、SeqLab、MRC、Seq2ASeq和(M)LM。

#### Classification (Class)

文本分类是为文本指定预定义的标签，在**情感分析、主题分类、垃圾邮件检测**等自然语言处理应用中是一项重要而基本的任务。在深度学习时代，**文本分类通常是将输入的文本输入基于深度神经的编码器**，**提取特定任务的特征，然后输入到浅分类器，预测标签，**

![image-20230915103718667](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915103718667.png)

Y可以是one-hot或multi-hot(在这种情况下，我们称之为多标签分类)。ENC(·)可以实例化为卷积网络(Kim, 2014)、循环网络(Liu等人，2016)或transformers(Vaswani等人，2017)。CLS(·)通常被实现为一个简单的多层感知器，在池化层之后。请注意，**池层可以对整个输入文本或一组令牌执行**。

#### Matching

文本匹配是**预测两个文本语义相关性**的一种范式。它被广泛应用于**信息检索、自然语言推理、问答系统和对话系统等领域**。匹配模型**不仅应该提取两个文本的特征**，**还应该捕获它们的细粒度交互**。匹配范式可以简单地表述为

![image-20230915103937841](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915103937841.png)

Xa和Xb是两个需要预测的文本，Y可以是离散的或连续的，这两个文本可以**分别编码**，然后**相互交互**(Chen等人，2017b)，或者连接到一个单一的深度编码器(Devlin等人，2019)。

#### Sequence Labeling (SeqLab)

序列标记(SeqLab)范式(也称为序列标记)是一种基本的范式，用于建模各种任务，如**词性标记(POS)、命名实体识别(NER)和文本分块。**

传统的基于神经网络的序列标记模型由**编码器和解码器**组成，编码器**捕获序列中每个标记的上下文化特征**，解码器**接收特征并预测标记**。

![image-20230915104144455](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915104144455.png)

其中，y1，···，yn为x1，···，xn对应的标签。ENC(·)可以实例化为循环网络(Ma and Hovy, 2016)或transformers编码器(Vaswani et al.， 2017)。DEC(·)通常被实现为**条件随机场**(CRF) (Lafferty et al.， 2001)。

#### MRC

机器阅读理解(MRC)范式**从给定问题条件下的输入序列中提取连续标记序列(跨度)**。

它首先用于求解MRC任务，然后将其推广到其他NLP任务，将其重新构造为MRC格式。但是，为了与之前的工作保持一致并避免混淆，我们将此范式命名为MRC，并将其与任务MRC区分开来。MRC范式可以被正式描述为:

![image-20230915110252070](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915110252070.png)

其中Xp和Xq表示段落(也指上下文)和查询，yk···yk+l是Xp或Xq的跨度。DEC被实现为两个分类器，一个用于**预测起始位置，一个用于预测结束位置**

#### Sequence-to-Sequence (Seq2Seq)

序列到序列(Seq2Seq)范式是一种通用而强大的范式，可以处理各种NLP任务。Seq2Seq的典型应用程序包括机器翻译和对话，其中系统应该根据**输入序列**(源语言或用户查询)**输出序列(目标语言或响应)**。Seq2Seq范式通常由**编码器-解码器**框架实现

![image-20230915110431571](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915110431571.png)

与SeqLab不同，输入和输出的长度**不一定相同**。此外，Seq2Seq中的解码器通常更复杂，在**每一步都将前一个输出(在测试时)或ground truth(在培训时教师强制)作为输入。**

#### Sequence-to-Action-Sequence (Seq2ASeq)

序列-动作-序列(Sequence-to-Action-Sequence, Seq2ASeq)是一种广泛应用的**结构化预测范式**。Seq2ASeq的目标是**预测从初始配置c0到终端配置的动作序列(**也称为转换序列)。预测的动作序列应该编码一些合法的结构，如依赖树。Seq2ASeq范例的实例通常称为**基于转换的模型**，可以表示为

![image-20230915110612612](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915110612612.png)

其中A = a1，···，am是一个动作序列，C = c0，···，cm−1是一个配置序列。在每个时间步中，模型**根据输入文本和当前配置ct−1预测一个动作At**，它可以**由堆栈、缓冲区和之前的动作的顶部元素组成**(Chen和Manning, 2014;Dyer等人，2015)。

#### (M)LM

语言建模(LM)是自然语言处理(NLP)中一个长期存在的任务，它是**估计一个给定的单词序列在一个句子中出现的概率。**

由于语言模型具有**自我监督**的特点，因此采用语言模型及其变体，如**蒙面语言模型**(mlm)作为训练目标，在大规模无标记语料库上对模型进行预训练。通常，语言模型可以简单地表示为

![image-20230915110805755](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915110805755.png)

其中DEC可以是任何**自回归模型**，如**回归网络**(Bengio et al.， 2000;Grave等人，2017年)和**Transformer解码器**(Dai等人，2019年)。作为LM的一个著名的变体，MLM可以表示为

![image-20230915110904515](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230915110904515.png)

其中~x是x的一个损坏的版本，通过用特殊的令牌[MASK]替换一部分令牌，¯x表示要预测的蒙面令牌。

### Compound Paradigm

更复杂的NLP任务可以通过组合多个基本范式来解决。例如，HotpotQA (Yang et al.， 2018b)是一个多跳问答任务，可以将Matching和MRC相结合来求解，其中Matching负责查找相关文档，MRC负责选择答案区间(Wu et al.， 2021)。

## Paradigm Shift in NLP Tasks

我们回顾了发生在不同NLP任务中的范式转变:文本分类、自然语言推理、命名实体识别、基于方面的情感分析、关系提取、文本摘要和解析。

### Text Classification

Class范式可以很好地解决传统的文本分类任务。然而，它的变体(如**多标签分类**)可能具有挑战性，在这种情况下，Class可能不是最优的。为此，Yang等人(2018a)提出采用**Seq2Seq范式**，以**更好地捕捉多标签分类任务中标签之间的交互作用**。

**隐藏在标签中的语义**不能在Class范例中充分利用。Chai et al.(2020)和Wang et al.(2021)采用**匹配范式**来预测成对输入(X, Ly)是否匹配，其中X是原始文本，Ly是对y类的标签描述。

随着预训练语言模型(pre- training language model, LMs)的兴起，文本分类任务也可以用**(M)LM范式**来解决,通过**将文本分类任务重新定义为(掩蔽的)语言建模任务**，可以缩小LM预训练和微调之间的差距，从而在训练数据有限的情况下提高性能。

### Natural Language Inference

自然语言推理(NLI)通常在**匹配范式中建模**，其中**两个输入文本(Xa, Xb)进行编码并相互交互**，然后**使用一个分类器来预测它们之间的关系**

随着BERT (Devlin et al.， 2019)等强大的编码器的出现，NLI任务可以通过**将两个文本连接为一个简单的类范例**来解决。

在少样本学习的情况下，NLI任务也可以通过修改输入在(M)LM范式中表示，例如“Xa ?”[MASK]，Xb”。未填充的令牌[MASK]可以被MLM预测为Yes/No/Maybe，对应于包含/矛盾/中性(Schick and Sch¨utze, 2021a,b;Gao等人，2021)。

### Named Entity Recognition

命名实体识别(name Entity Recognition, NER)也是自然语言处理中的一项基本任务。NER可以分为三个子任务:**平面NER、嵌套NER和不连续NER**。传统方法通常基于三个范式分别求解这三个NER任务，即**SeqLab** (Ma and Hovy, 2016;Lample et al.， 2016)， **Class** (Xia et al.， 2019;Fisher和Vlachos, 2019)，和**Seq2ASeq** (Lample等人，2016;戴等人，2020)。

Yu等人(2020)和Fu等人(2021)用**Class**范式求解平面NER和嵌套NER。其主要思想是**预测输入文本中每个跨度的标签**。这种范式转移引入了跨度重叠问题:**预测的实体可能会重叠**，这在平面NER中是不允许的。为此，Fu等(2021)采用了启发式解码方法:对于这些重叠的跨度，**只保留预测概率最高的跨度**。

Li等人(2020)提出将扁平和嵌套的NER作为MRC任务。他们将每个样本重构为一个三元组(X,Qy, Xspan)，其中**X是原始文本，Qy是实体y的问题，Xspan是答案。**给定上下文、问题和答案，可以采用MRC范式来解决这个问题.由于一个句子中可能有多个答案(实体)，因此开发了一个**索引匹配模块来对齐开始和结束索引**。

Yan等人(2021b)使用一个基于Seq2Seq范式的统一模型来解决所有三种NER子任务。

### Aspect-Based Sentiment Analysis

基于方面的情感分析(ABSA)是一种细粒度的情感分析任务，它包含7个子任务，即**方面词抽取(AE)、意见词抽取(OE)、方面级情感分类(ALSC)、面向方面的意见抽取(AOE)、方面词抽取与情感分类(AESC)、对抽取(Pair)、面向方面的情感分类(AOE)和三联体提取(三联体)。**ALSC可以用Class范例来解决，AESC可以用SeqLab范例来解决。

ALSC是预测每个目标方面对的情绪极性，Mao等(2021)采用**MRC范式**处理所有ABSA子任务。特别是，它们**构造两个查询，以顺序提取方面术语及其对应的极性和意见术语**。第一个查询是“在文本中查找方面术语”。假设MRC模型预测的答案(方面词)为AT，那么第二个查询可以构造为“找出文本中关于方面的情绪极性和意见词”。通过这样的数据集转换，所有ABSA子任务都可以在MRC范式中求解。Yan等人(2021a)使用**Seq2Seq范式**解决所有ABSA子任务，方法是**将一个子任务的原始标签转换为一组令牌序列**，作为训练Seq2Seq模型的目标。Li等人(2021)提出在**(M)LM范式**中制定ABSA子任务。特别是，对于输入文本X，以及感兴趣的方面A和意见O，它们构造了一个一致性提示和一个极性提示，如下:[面具]。这是[MASK]，第一个[MASK]可以用yes或no来表示一致或不一致的A和O，第二个[MASK]可以用情绪极性的词来表示。

### Relation Exaction

关系抽取有两个主要的子任务:**关系预测(根据上下文预测两个给定实体之间的关系)和三元组抽取(从输入文本中提取三元组(s, r, o))**。前一个子任务主要用**Class**范式解决(Zeng et al.， 2014;Sun et al.， 2020)，而后一个子任务通常采用**流水线方式**解决，首先使用**SeqLab范式提取实体**，然后使用**Class范式预测实体之间的关系**。

Zeng等人(2018)利用**Seq2Seq范式**解决了三联体抽取任务。在他们的框架中，Seq2Seq范式的**输入是原始文本**，而**输出是一个三元组的序列**{(r1, s1, o1)，···(rn, sn, on)}。采用复制机制(Gu et al.， 2016)提取文本中的实体。

Levy等人(2017)通过**生成关系特定问题的MRC范式**来解决RE任务。

Han等人(2021)通过**使用逻辑规则构造带有多个子提示符的提示符**，将RE任务定义为一个MLM任务。通过将实体和关系的先验知识编码到提示中

### Text Summarization

文本摘要的目的是生成一个简洁的和信息摘要的大型文本。解决文本摘要问题有两种不同的方法:**抽取式摘要和抽象式摘要**。提取摘要方法提取原始文本中的子句以形成最终的摘要，这通常存在于SeqLab范式中。而抽象摘要方法通常采用Seq2Seq范式，以原文为条件直接生成摘要。

McCann等人(2018)将**总结任务重新定义为一个问答任务**，其中的**问题是“总结是什么?**”由于答案(即摘要)不一定由原始文本中的标记组成，传统的MRC模型无法处理这一问题。因此，作者开发了一个**seq2seq模型**来解决这种格式的摘要任务。

Zhong等(2020)提出用**Matching范式**代替SeqLab范式来解决抽取式摘要任务。其主要思想是**将原始文本和每个候选摘要的语义进行匹配**，找到匹配得分最高的摘要。

Aghajanyan等人(2021)在**(M)LM范式中**制定了文本摘要任务。他们直接**在大规模的结构化HTML网页上预先训练一个bart风格的模型**。

### Parsing

解析(分组解析、依赖解析、语义解析等)在机器翻译、问答等自然语言处理应用中起着至关重要的作用。

这类任务是从自然语言话语中**推导出结构化的句法或语义表示**。两种常用的解析方法是**基于转换的方法和基于图的方法**。通常，基于转换的方法属于**Seq2ASeq**范式，而基于图的方法属于**Class**范式。

通过将目标树结构线性化为一个序列，解析可以在Seq2Seq范式中解决

### Trends of Paradigm Shift

## Potential Unified Paradigms in NLP(NLP的潜在统一范式)

一些范例已经展示了将各种NLP任务组织成一个统一框架的潜在能力。这样的范例提供了一种可能性，即**单个部署的模型可以作为不同NLP任务的统一求解器**，而不是单独解决每个任务。**单一统一模型相对于多个特定于任务的模型的优势**可以总结如下:

1. Data efficiency:训练特定于任务的模型通常需要大规模的特定于任务的标记数据。相比之下，统一模型显示出了在使用更少标签数据的情况下实现可观性能的能力。
2. Generalization.:特定于任务的模型很难转化为新的任务，而统一的模型可以通过适当的格式将其概括为不可见的任务。
3. Convenience.Convenience.

在本节中，我们将讨论以下通用范例，它们有可能统一不同的NLP任务:(M)LM、Matching、MRC和Seq2Seq。

### (M)LM

将下游任务重新定义为(M)LM任务是利用预先训练好的LM的一种自然方式。原始输入**被一个预定义的或学习过的提示符修改**，提示符中包含一些未填充的槽，这些槽可以由预训练的lm填充。然后可以从填充的标记派生出任务标签。

#### Prompt

提示的选择对于执行特定任务至关重要。好的提示可以(1)**手工设计**。Brown等人(2020年);Schick和Sch¨utze (2021a,b)**为不同的任务手工制作特定于任务的提示**。虽然它是启发式的，有时不直观，但手工编写的提示已经在各种少样本任务中取得了具有竞争力的性能。(2)**从语料库中挖掘**。Jiang等(2020)通过挖掘语料库中**具有相同主语和宾语的句子**，构建关系抽取提示语。(3)**意译产生**。Jiang等人(2020)使用**反向翻译将原提示改写成多个新的提示**。(4)由**另一种预训练语言模型生成**。Gao等人(2021)使用**T5** (Raffel等人，2020)**生成提示符**，因为T5是预先训练来填补输入中缺失的跨度。(5)**梯度下降学习**。Shin等人(2020)基于**梯度引导搜索自动构造提示符**。如果提示符不一定是离散的，它可以在连续空间中有效地优化。

#### Verbalizer

语言器的设计对基于提示的学习也有很大的影响(Gao等人，2021年)。语言器可以(1)**手工设计**。Schick和sch¨utze (2021a)启发式地为不同的任务设计了语言器，并取得了竞争性的结果。然而，对于许多任务(例如，当类标签不直接对应词汇表中的单词时)，手动设计适当的表述器并不总是直观的。(2)**自动搜索一组标记数据**(Schick et al.， 2020;Gao等人，2021年;Shin等人，2020年;刘等，2021b)。(3)**利用知识库构建和提炼**(Hu et al.， 2021)。

#### Parameter-Efficient Tuning

与需要针对每个任务调优所有模型参数的微调相比，基于提示的调优在参数效率上也有优势。由于参数的有效性，基于提示的调优技术是一种很有前途的大规模预训练lm部署技术。

在传统的微调中，服务器必须为每个下游任务维护整个预训练LM的特定于任务的副本，并且推理必须在单独的批中执行。在基于提示的调优中，**只需要一个预先训练的LM**，并且可以通过使用特定于任务的提示修改输入来执行不同的任务。此外，不同任务的输入可以混合在同一批次中，使得服务非常高效。

### Matching

另一个潜在的统一范式是匹配，或者更具体地说是文本蕴涵(也称为自然语言推理)。文本蕴涵是预测两个给定句子的任务，**前提和假设**:前提是否包含假设，或与假设相矛盾，或两者皆非。

#### Domain Adaptation

隐含模型可能偏向源域，导致对目标域泛化效果较差。为了缓解源任务和目标任务之间的领域差异，Yin等(2020)提出了跨任务最近邻模块，该模块匹配源域和目标域的实例表示和类表示，这样，隐含模型可以在标注有限的情况下很好地泛化到新的NLP任务。

#### Label Descriptions

对于单句分类任务，需要将每个类的标签描述与输入文本连接起来，以便由隐含模型预测。标签描述可以看作是触发隐含模型的一种提示。

Wang等人(2021)表明，具有**最小领域知识的手工制作的标签描述**可以在各种少样本任务上实现最先进的性能。然而，人类书写的标签描述可能不是最优的，Chai等人(2020)利用**强化学习生成标签描述**。

#### Comparison with Prompt-Based Learning

两个范式((M)LM和Matching)中，目标是**将下游任务重新规划为训练前任务**(语言建模或包含)。为了实现这一点，两者都需要**使用一些模板修改输入文本**，以提示预先训练的语言或蕴涵模型。

在**基于提示**的学习中，预测由预训练的MLM头部对[MASK]令牌进行，而在**基于匹配**的学习中，预测由预训练的分类器对[CLS]令牌进行。在基于提示的学习中，**输出预测是在词汇表上进行的**，因此需要一个语言表达器将词汇表中预测的单词映射到任务标签中。相比之下，基于匹配的学习可以**简单地重用输出**(蕴涵/矛盾/中立，或蕴涵/不蕴涵)。基于匹配学习的另一个优点是可以**构造成对增强数据进行对比学习**，进一步提高少样本性能。

### MRC

MRC也是一种可以统一各种NLP任务的替代范式，它通过生成特定任务的问题，并训练MRC模型从基于问题的输入文本中选择正确的跨度。

只要任务输入可以被重新表述为上下文、问题和答案，MRC范式就可以被应用。

#### Comparison with Prompt-Based Learning

设计的问题可以类似于(M)LM中的提示。在MRC中**不需要使用动词，**因为答案是上下文或问题中的跨度。在基于提示的学习中，预测器，即传销头，可以被传统MRC模型中的开始/结束分类器或McCann等人(2018)中的指针网络所取代。

### Seq2Seq

Seq2Seq是一个通用而灵活的范例，它可以处理任何其输入和输出可以被重新转换为标记序列的任务。

#### Comparison with Other Paradigms

与其他统一范式相比，Seq2Seq特别适合于**结构化预测**等复杂任务。另一个好处是Seq2Seq也兼容其他范例，如(M)LM  MRC等.大多数成功的seq2seq模型都是**自回归**的，其中每一代步骤都依赖于之前生成的令牌。这种顺序性导致了推理时间的固有延迟。

## Conclusion

基于提示的调优(将一些NLP任务格式化为(M)LM任务)迅速流行起来。他们可以用更少的训练数据实现相当大的性能。

然而，与(M)LM相比，这些范式有其优势:**匹配需要更少的工程，MRC更易于解释，Seq2Seq更灵活地处理复杂的任务。**