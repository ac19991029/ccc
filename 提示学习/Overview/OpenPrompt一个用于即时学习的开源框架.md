# OpenPrompt:一个用于即时学习的开源框架

## abstract

提示学习已成为现代自然语言处理的一种新范式，它直接将预训练语言模型(PLMs)用于完形预测、自回归建模或序列生成，在各种任务中都有良好的表现。然而，目前还没有提出提示学习的标准实现框架，而且大多数现有的promptlearning代码库通常不受监管，仅为特定场景提供有限的实现。由于在提示学习中需要考虑许多细节，如模板策略、初始化策略和语言化策略等，所以实践者面临着将所需的快速学习方法快速应用于其应用的障碍。在本文中，我们提出了OpenPrompt，一个用于在PLMs上进行提示学习的统一的easyto-use工具箱。OpenPrompt是一个研究友好型框架，具有效率、模块化和可扩展性，它的可组合性允许将不同的plm、任务格式和提示模块自由地组合在一个统一的范例中。用户可以在不受约束的情况下，方便地部署提示学习框架，并在不同的NLP任务上评估其泛化程度。

## introduction

预训练语言模型(PLMs) (Han et al.， 2021a;邱等人，2020)已被广泛证明在自然语言理解和生成方面是有效的，这开启了现代自然语言处理(NLP)的新时代。在这场革命的早期阶段，一种使plm适应各种特定NLP任务的标准方法是**训练前-微调范式**，**在调优过程中引入额外的参数和任务特定的目标**。然而最近，plm的适应范式正在发生转变。起源于T5 (Raffel et al.， 2019)和GPT3 (Brown et al.， 2020)的研究发现，plm可以**通过文本提示或演示有效地激发，特别是在低数据场景下。**

以一个简单的基于提示的情感分类为例，该管道由一个模板和一个表达器组成，其中一个模板用于处理带有一些额外标记的原始文本，而表达器则将原始标签投射到词汇表中的单词中以进行最终预测。假设模板是“<text> It is <mask>”，其中令牌<text>表示原始文本，表达器是{" positive ": " great "， " negative ": " terrible "}。这句话“爱因斯坦是他那个时代最伟大的智者之一。”将首先用预设的模板来包装:“阿尔伯特·爱因斯坦是他那个时代最伟大的智者之一。”它是<mask> "。然后对被包装的句子进行标记化，并将其输入到PLM中，以预测<mask>标记位置上词汇表的分布。可以想见，“伟大”这个词出现的概率应该比“可怕”大。

在文本或软编码提示的帮助下，提示学习将下游任务投射到PLMs的培训前目标。一系列关于提示学习的研究(Liu et al.， 2021a)被提出来研究构建模板的策略(Schick and Sch¨utze, 2021;Gao等人，2021年;Liu等人，2021b)、叙述者(Hu等人，2021)、优化(Lester等人，2021)和应用(Li和Liang, 2021;Han et al.， 2021b;丁等人，2021a)。

提示学习问题可以看作是PLMs、人类先验知识和需要处理的特定NLP任务的综合。很难用当前的深度学习或NLP库支持提示学习的特定实现，同时也缺乏标准的范例。以往的工作追求以最有效的方式实现即时学习，而对现有框架的传统微调修改最少，导致可读性差，甚至不稳定的重现性。此外，提示学习管道的性能随模板和语言器的选择而变化很大

为此，我们提供了OpenPrompt，这是一个用于提示学习的开放源码、易于使用和可扩展的工具箱。OpenPrompt模块化整个提示学习框架，并考虑各个模块之间的交互。我们强调了OpenPrompt的可组合特性，它支持多种任务格式、plm和提示模块的灵活组合。例如，我们可以很容易地将前缀调优(Li和Liang, 2021)用于OpenPrompt中的文本分类任务。该特性使用户能够评估他们的提示学习模型在各种任务上的泛化程度，而不仅仅是在特定任务上的性能。

具体地说，在OpenPrompt中，Template类用于定义或生成文本或软编码模板来包装原始输入。为了在统一的范型下灵活地支持各种模板，我们设计了一种新的模板语言，可以方便地对相应的属性进行令牌级定制。例如，用户可以指定哪些令牌是共享的、嵌入可培训的，或者以何种方式对这些令牌进行后处理，而不必为特定的模板执行复杂的实现。Verbalizer将分类标签投射到词汇表中的单词，PromptModel负责训练和推理过程。OpenPrompt中的每个模块都有明确的定义，同时保持其独立性和耦合性，因此研究人员可以轻松地部署模型并进行有针对性的改进。我们还使用OpenPrompt实现基线，并在广泛的NLP任务中评估它们，证明了OpenPrompt的有效性。

plm在NLP的几乎所有子任务上都取得了巨大的成功，但仍有一个问题悬而未决，那就是我们是否真的充分利用了plm的潜力，尤其是那些大型的?传统的微调使用**额外的特定于任务的头部和目标来适应**，但这种策略可能面临两个问题。一方面，**这种方法在模型调优和预训练之间产生了天然的差距**。另一方面，**随着模型参数数量的增加，由于计算量巨大**，这种微调方法变得越来越难以操作

通过模拟预训练过程，提示学习直观地架起了预训练和模型调优之间的桥梁。实际上，这种范式在低数据状态下非常有效

## 设计与实现

![image-20230911142146144](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230911142146144.png)

### Combinability

在NLP世界中，我们通常采用不同的plm，针对不同的底层任务(大致是分类和生成)采用相应的目标函数。但在提示学习中，考虑到框架的核心思想是模仿下游任务中的训练前任务，本质上是“**根据上下文预测单词**”，我们可以进一步统一下游任务的执行。OpenPrompt以一种灵活的方式支持任务(分类和生成)、PLMs (MLM、LM和Seq2Seq)和提示模块(不同的模板和语言表达器)的组合。

提示方面，还可以使用前缀调优进行分类，使用软提示进行生成。

### Pre-trained Language Models

提示学习的一个核心思想是使用带屏蔽标记的附加上下文来模拟PLMs的培训前目标，并更好地刺激这些模型。因此，选择PLMs对整个提示学习过程至关重要。plm可以根据培训前的目标大致分为三组。

第一组plm使用掩蔽语言建模(MLM)来重建被随机掩蔽令牌破坏的序列，其中只计算掩蔽令牌的损失。具有传中目标的典型plm包括BERT (Devlin et al.， 2019)、RoBERTa (Liu et al.， 2019)等，这些目标被认为适合于自然语言理解(NLU)。

第二组利用自回归式语言建模(LM)来根据其领先的标记预测当前的标记。GPT-3 (Brown et al.， 2020)是采用这一目标的代表作之一。

第三部分是序列到序列(Seq2Seq)模型，其目的是生成一个序列，该序列具有一个解码器，其条件是对输入序列使用一个单独的编码器。典型的seq2seq plm包括T5 (Raffel et al.， 2020)、MASS (Song et al.， 2019)和BART (Lewis et al.， 2020)等。

### Tokenization

标记化是自然语言处理中数据处理的关键步骤，在提示学习中面临着新的挑战。在设计模板之后，原始输入和设计模板的标记化的具体实现可能很耗时，而且容易出错。

首先，在提示学习过程中，token化过程中要认真处理实体索引、掩码代币等特定信息。一些小的错误，例如隐藏令牌索引的不匹配，可能会导致严重的后果。此外，还应该处理标记化之后的连接和截断问题(模板不应该被截断)。由于不同的plm可能有不同的标记化策略，我们还应该考虑额外上下文处理细节上的不一致性。

在OpenPrompt，我们专门设计了用于提示学习的标记化模块，大大简化了这个过程。通过使用我们封装的数据处理api，用户可以使用人类可读的风格来设计模板，同时方便地对输入和模板进行操作。我们的组件集成了来自输入和模板的复杂信息，然后进行标记化。OpenPrompt根据PLMs (MLM, LM, Seq2Seq)的选择，在提示学习中自动选择合适的令牌器，为用户处理提示相关数据节省了大量的时间。

### Templates

作为提示学习的核心部分之一，模板模块用文本或软编码模板包装原始文本。模板通常包含上下文标记(文本或软标记)和掩码标记。在OpenPrompt中，所有模板都继承自具有通用属性和抽象方法的公共基类。

为每一个提示设计一个模板格式是不合理的，因为在实际使用时需要很高的学习成本。为此，在OpenPrompt中，我们设计了一种模板语言来缓解这个问题，使用这种语言，我们可以在一个统一的范例下构造各种类型的模板。我们的模板语言从Python的字典语法中获得启发。这种设计在保证灵活性和清晰度的同时，允许用户相对容易地构建不同的提示。

模板节点是一个带有属性描述的文本(或空文本)。在我们的模板语言中，我们可以自由编辑模板中每个标记的属性，比如哪些字符被共享嵌入，字符如何被后处理

### Verbalizers

当涉及到基于提示的分类时，应该构造一个语言表达器类来将原始标签映射到词汇表中的单词。当PLM预测一个掩码位置词汇表上的概率分布时，语言表达器将提取标注词的对数，并将标注词的对数集成到相应的类中，从而负责计算损失。

### PromptModel

在OpenPrompt中，我们使用PromptModel对象来负责训练和推理，它包含一个PLM、一个Template对象和一个Verbalizer对象(可选)。用户可以灵活组合这些模块，并定义模块之间的高级交互。在基类中实现了一种模型无关的正演方法来预测被掩蔽位置。这个模块的一个目标是，用户不需要为不同的plm具体实现头，而是使用一个统一的API来“预测需要预测的职位的词”，而不管培训前的目标是什么。

### Training

从可训练参数的角度看，提示学习训练可分为两类策略。

1. 第一种策略同时调优提示和PLM，这在低数据环境中被证明是有效的(OpenPrompt还提供了一个FewshotSampler来支持少样本学习场景)。
2. 第二种策略是只训练提示的参数，保持PLM的冻结状态，这被认为是一种参数高效的调整方法，是一种很有希望的刺激超大型PLM的方法。

OpenPrompt中的培训器模块实现了培训过程，并伴随着面向提示的培训技巧，例如模板的集合。同时，OpenPrompt支持通过配置进行实验，以轻松推动大规模的实证研究。

## Evaluation

![image-20230911145207602](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230911145207602.png)

## Conclusion

我们建议使用OpenPrompt，这是一个统一的、易于使用的、可扩展的提示学习工具箱。OpenPrompt建立了一个统一的框架，它具有明确定义的块和灵活的交互，以支持可靠的提示学习研究。