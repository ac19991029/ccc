# 我们如何知道语言模型知道什么?

## 代码：https://github.com/jzbjyb/LPAQA.

## Abstract

最近的研究显示了有趣的结果，通过让语言模型(LM)来填补诸如“奥巴马是一个职业”之类的提示符的空白，来检验语言模型(LM)中包含的知识。

这些提示通常是手工创建的，而且很可能不是最优的;而像“奥巴马曾是某某人”这样的提示则能更准确地预测出正确的职业。因此，如果给出不适当的提示，我们可能无法检索LM所知道的事实，因此任何给定的提示都只能提供LM中所包含知识的下界估计。

在本文中，我们试图通过自动发现在查询过程中使用的更好的提示来更准确地估计lm中包含的知识。具体来说，我们提出了**基于挖掘和释义的方法来自动生成高质量和多样化的提示**，以及**集成方法来组合不同提示的答案**。在从lm中提取相关知识的LAMA基准上进行的大量实验表明，我们的方法可以将准确率从31.1%提高到39.6%，为lm所知道的知识提供了更严格的下限。

## Introduction

语言模型(LM)的主要作用已经**从生成或评估自然文本的流畅性**(Mikolov和Zweig, 2012;梅里蒂等人，2018年;Melis等人，2018年;Gamon等人，2005)**成为一个强大的文本理解工具**。这种理解主要是通过使用语言建模作为特征提取器的前训练任务来实现的，其中**通过语言建模目标学习到的隐藏向量然后被用于下游的语言理解系统**

LMs本身也可以作为一种文本理解工具，使用**自然语言表达查询**，或者**直接生成文本答案**，或**评估多项选择并选择最可能的一个**

LM中包含的知识都是通过提供提示来探测的，并让**LM生成一个前缀的延续或者预测完形模板中缺少的单词**

关于lm表达的知识，他们通常依赖于根据实验者的直觉手工创建的提示。由于提示不是对该事实的有效查询，很可能无法检索LM知道的事实。因此，现有的结果只是lm所包含的知识范围的一个下界，事实上，lm可能比这些最初的结果显示的更有知识。

在本文中，我们提出了这样一个问题:“**我们如何收紧这个下界，并对最先进的lm中包含的知识进行更准确的估计?”**

我们特别关注Petroni等人(2019)的设置，他们检查了**关于实体之间关系的知识提取**(定义见§2)。我们提出了两种自动方法，系统地提高用于**查询关系是否存在的提示符的广度和质量**(见§3)。具体而言，如图1所示:它们是受以前的关系提取方法启发的基于挖掘的方法(Ravichandran和Hovy, 2002)，以及接受种子提示(手动创建或自动挖掘)并将其转述为其他几个语义类似的表达式的基于转述的方法。此外，由于在查询不同的主语-宾语对时，不同的提示符可能会更好地工作，我们还研究了轻量级集成方法来将不同提示符的答案组合在一起

![image-20230922152306212](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922152306212.png)

我们在LAMA基准(Petroni et al.， 2019)上进行了实验，这是一种英语基准，旨在测试lm检索实体之间关系的能力。我们首先证明，改进的提示显著提高了任务的准确性，通过我们的方法提取一个最佳提示，BERT-base上的准确率从31.1%提高到34.1%。我们进一步证明，通过集合的方式使用多样化的提示符，进一步提高了39.6%的准确率。

## Knowledge Retrieval from LMs

从lm检索事实性知识与查询标准的声明性知识库(KB)有很大的不同。在标准的KBs中，用户**将其信息需求表述为由KB模式和查询语言定义的结构化查询**。例如，SELECT ?y WHERE {wd:Q76 wdt:P19 ?y}是一个**SPARQL查询**，用于搜索Barack_Obama的出生地。相反，**lm必须通过自然语言提示进行查询**，例如“Barack Obama was born In”，空白中被指定概率最高的单词将被返回为答案。

虽然提示符的概念是常见的方法，从lm中提取多种知识，在本文中，我们具体遵循Petroni等人(2019)的公式，其中事实知识的形式是三元组<x, r, y>。这里x表示主语，y表示宾语，r是它们的对应关系。

r与完形风格的提示符tr相关联，tr由一系列符号组成,要查询LM其中两个是主题和对象的占位符(例如，“x位于y位置”)。通过用物体的表面形式替换x，并让模型预测缺失的物体

![image-20230922153107544](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922153107544.png)

其中**V是词汇表**，**PLM(y'|x, tr)是在空白条件下(即主题和提示符)预测y'的LM概率**。果ˆy与基本事实y相同，我们就说LM知道一个事实。因为我们希望我们的提示能够最有效地引出LM本身包含的任何知识，一个“好的”提示应该触发LM，尽可能多地预测基本事实对象。

我们提出了一些方法，这些方法可以从**一小组训练数据中学习有效的提示**，这些训练数据由每个关系的黄金主题-对象对组成。

## Prompt Generation

首先，我们处理提示生成:**为每个关系r生成一组提示{tr,i}T i=1的任务**，其中至少有一些提示会有效地触发lm来预测地面真实对象。我们采用了两种实用的方法，一是**从大型语料库中挖掘提示候选者**，一种是**通过释义使种子提示多样化**。

### Mining-based Generation

第一种方法受到基于模板的关系提取方法的启发.在大型语料库中，**主语x和宾语y附近的单词通常描述关系r**。基于这种直觉，我们首先**利用远距离监督的假设**，识别出**所有包含特定关系主语和宾语的维基百科句子**，然后提出两种提取提示信息的方法。

#### Middle-word Prompts

位于主语和宾语中间的词Dependency-based Prompts往往是这种关系的象征，我们直接使用这些词作为提示。

#### Dependency-based Prompts

Toutanova et al.(2015)注意到在模板中单词没有出现在中间的情况下.基于句子句法分析的模板可以更有效地提取关系。

第二种创建提示的策略中遵循这一观点，该策略**使用依赖解析器解析句子**，以**确定主语和宾语之间的最短依赖路径**，然后**使用依赖路径中从最左边的单词到最右边的单词之间的短语作为提示**。上图中的依赖路径为“France pobj←−−of prep←−−capital nsubj←−−is attr−−→Paris”，其中最左边和最右边的单词分别为“capital”和“Paris”，提示为“capital ofx is y”。

这些基于挖掘的方法不依赖于任何手工创建的提示，因此可以灵活地应用于任何关系，其中我们可以获得一组主题-对象对。

### Paraphrasing-based Generation

生成提示符的第二种方法更具针对性——它旨在提高词汇多样性，同时相对忠实于原始提示符。具体来说，我们通过将**原始提示改写为其他语义相似或相同的表达式来实现**这一点。

例如，如果我们最初的提示是“x与y共享一个边界”，那么它可能会被改写为“x与y有一个共同的边界”和“x与y相邻”。

我们使用简单的反向翻译方法,首先将初始提示翻译成另一种语言的B候选者，然后将每一个提示翻译成原语言的B候选者。然后根据往返概率(即Pforward(¯t|ˆt)·Pbackward(t|¯t)，其中ˆt是初始提示符，¯tis是翻译后的另一种语言提示符，t是最后的提示符)，保留前面的t提示符。

## Prompt Selection and Ensembling

### Top-1 Prompt Selection

对于每个提示符，我们可以使用以下方法来**测量其预测地面真实对象(在一个训练数据集上)的准确性**:

![image-20230922154754158](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922154754158.png)

其中R是关系为r的主客体对的集合，δ(·)是克罗内克函数，如果内部条件为真则返回1，否则返回0。在查询LM的最简单方法中，我们选择准确度最高的提示符，只使用该提示符进行查询。

### Rank-based Ensemble

我们将研究不仅使用top1提示符，而且还将多个提示符组合在一起的方法。这样做的好处是，LM可能在其训练数据中**观察到不同上下文中的不同实体对**，并且**有各种提示可能允许提取出现在这些不同上下文中的知识**。

我们的第一个集成方法是一个**无参数方法**，它**对排名靠前的提示符的预测进行平均**。我们根据提示对训练集中对象的预测精度对所有提示进行排序，并使用前K条提示的平均log概率来计算对象的概率:

![image-20230922155241399](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922155241399.png)

其中tr,i是第i位的提示符。这里，K是一个超参数，小K关注于少数最准确的提示，大K增加提示的多样性。

### Optimized Ensemble

上述方法将前K条提示同等对待，这是次优提示，因为**有些提示比其他提示更可靠**。因此，我们也提出了一种直接优化提示权值的方法。形式上，我们将公式1中的分数重新定义为:

![image-20230922155627057](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922155627057.png)

Pθr (tr,i|r) = softmax(θr)是由t大小的真实值向量θr参数化的提示符上的分布。对于每个关系，我们学习为不同的T候选提示集打分，所以参数的总数是T乘以关系的数量。对参数θr进行优化，以使金标准对象P(y|x, r)在训练数据上的概率最大化。

## Main Experiments

### Experimental Settings

#### Dataset

我们使用LAMA基准的T-REx子集，它有一个更广泛的41个关系集，每个关系与来自Wikidata的至多1000个主题-对象对关联，以及一个手工设计的单一提示。

为了学习挖掘提示(§3.1)、排序提示(§4.2)或学习集合权重(§4.3)，我们也从Wikidata为每个与T-REx数据集没有重叠的关系创建一个单独的主题-对象对训练集。我们将训练集表示为TREx-train。为了与LAMA中的T-REx数据集保持一致，T-REx-train也被选择只包含单令牌对象。为了调查我们的方法的通用性，我们也报告了我们的方法在Google-RE子集5上的性能，它采取了类似于T-REx的形式，但相对较小，只涵盖了3个关系。

在LAMA中，一些事实可以**仅仅根据实体的表面形式回忆，而不需要记忆事实**。他们过滤掉那些容易猜测的事实，并创建一个更困难的基准，称为LAMA-UHN。我们还对LAMA-UHN的T-REx子集(即T-REx- uhn)进行了实验，以研究我们的方法在这个更困难的基准测试上是否仍然可以获得改进。表1总结了数据集统计。

![image-20230922160016795](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922160016795.png)

#### Models

使用了标准**BERT-base和BERT-large**模型(Devlin et al.， 2019)。我们还对其他经过外部实体表征增强的预训练模型(即**ERNIE** (Zhang et al.， 2019)和**KnowBert** (Peters et al.， 2019))进行了一些实验，我们认为这些模型在实体回忆方面可能做得更好。

#### Evaluation Metrics

使用两个指标来评估提示在探测lm中的成功程度。第一个评价指标，**微观平均精度**，在计算关系r的所有主体-对象对的精度时，遵循LAMA基准

![image-20230922160244804](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922160244804.png)

y是预测，y是基本事实。然后我们平均所有关系。然而，我们发现一些关系的对象分布是极端倾斜的，例如，关系母语中超过一半的对象是法语。这可能会导致看似很高的分数，即使是在多数阶级的基线上，为每个关系选择最常见的对象，也会得到22.0%的分数。为了缓解这个问题，我们还报告了**宏观平均精度**，它分别计算每个唯一对象的精度，然后将它们相加，得到关系级别的精度

![image-20230922161139335](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230922161139335.png)

其中uni_obj(R)返回关系R中的一组唯一对象。这是一个更严格的度量，大多数类基线只获得2.2%的分数。

#### Methods

我们尝试了不同的提示生成和选择/集合方法，并将其与Petroni等人(2019)使用的手工设计提示进行了比较。**Majority**指的是**预测每个关系的多数对象**。**Man**是Petroni等人(2019)的基线，仅使用**手动设计的提示进行检索**。**Mine**使用了**从维基百科中通过中间词和依赖路径挖掘的提示**，而**Mine+Man**将它们与手动提示**结合在一起**。**Mine+Para**对**每个关系挖掘出的最高级别提示进行意译**，而**Man+Para则使用手动提示。**

这些提示符的组合方式，要么是平均TopK排名最高的提示符的日志概率，要么是优化后的权重（OPti）。Oracle表示生成的提示的性能上限，如果其中任何一个提示允许LM成功预测对象，则判断事实是正确的。

#### Implementation Details

在所有的实验中，我们使用**T = 40**个最频繁的提示，无论是通过挖掘还是转述生成的，反向翻译的候选数量设置为**B = 7**。

我们删除只包含停止字/标点符号或超过10个字的提示，以减少噪音。我们使用在WMT ' 19 (Ng et al.， 2019)上预先训练的双向英德神经机器翻译模型进行反向翻译，因为英德是资源最丰富的语言对之一在优化集成参数时，我们使用Adam (Kingma and Ba, 2015)，默认参数和批量大小为32。

### Evaluation Results

表2和表3分别报告了不同方法的微观和宏观平均精度。

![image-20230925100931521](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925100931521.png)

![image-20230925101053960](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925101053960.png)

#### Single Prompt Experiments

当只使用一个提示时(在两个表的Top1列中)，所提出的最佳提示生成方法在BERT-base上的微平均准确率从**31.1%提高到34.1%**，在BERT-large上的微平均准确率从**32.3%提高到39.4%。**这说明手动创建的提示符是一个较弱的下界;还有其他提示，进一步提高了从lm查询知识的能力。

表4显示了一些挖掘出来的提示，与手工提示相比，这些提示带来了较大的性能增益。对于关系宗教，“x who conversion to y”比手工定义的提示“x隶属于y宗教”提高了**60.0%**，对于关系subclass_of，“x是y的一种类型”比“x是y的一个子类”提高了**22.7**%。可以看到，使用挖掘的提示符获得的**最大好处**似乎出现在以下情况:**手动定义的提示符语法更复杂(例如前者)，或者使用比挖掘的提示符更不常见的措辞(例如后者)。**

![image-20230925101637146](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925101637146.png)

#### Prompt Ensembling

将列1中的单提示结果与下面三列中的集成结果进行比较，我们可以看到集成多个提示几乎总是会带来更好的性能。在不同的提示生成方法中，Top3和Top5中使用的简单平均值要优于Top1。

结果表明，不同的提示符确实可以以不同的方式查询LM，并且基于优化的方法能够找到有效地将不同提示符组合在一起的权重。

在表5中，我们列出了挖掘出的前3个提示符的学习权重和仅使用top1提示符获得的准确度。权重倾向于集中于一个特定的提示，其他提示作为补充。![image-20230925103311175](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925103311175.png)

#### Mining vs. Paraphrasing

对于基于排名的集合(Top1、3、5)，**用释义生成的提示通常比挖掘的提示执行得更好**，而对于基于优化的集合(Opti.)，**挖掘的提示执行得更好**。

我们推测，这是因为**挖掘的提示比意译更具多样性，适当的权重至关重要**。这种差异可以在每个类的提示符之间的平均编辑距离上观察到，挖掘提示符和释义提示符的平均编辑距离分别为3.27和2.73。然而，与仅使用一个提示符(Top1 vs Opti.)相比，整体释义的准确率仍有显著提高，在BERT-base条件下的微平均准确率从32.7%提高到36.2%，在BERTlarge条件下的微平均准确率从37.8%提高到40.1%。这表明，即使对提示进行很小的修改，也会导致预测出现较大的变化。

#### Middle-word vs. Dependency-based

在表7中，我们比较了仅使用中间词提示符并将它们与基于依赖项的提示符连接的性能。这些改进证实了我们的直觉，即属于依赖路径但不在主体和客体中间的词也表明了这种关系。

![image-20230925104223713](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925104223713.png)

#### Micro vs. Macro

比较表2和表3，我们可以看到宏观平均精度远低于微观平均精度，表明宏观平均精度是一个更具挑战性的度量，评估lm知道多少唯一对象。我们的优化方法将bert基上的宏观平均精度从22.8%提高到25.7%，bert基上的宏观平均精度从25.7%提高到30.1%。这再次证实了集成多个提示符的有效性，但效果要小一些。

#### Performance of Different LMs

在表8中，我们将BERT与ERNIE和KnowBert进行了比较，它们**通过明确地结合实体嵌入而通过外部知识得到增强**。即使在手工定义提示符的情况下，ERNIE也比BERT高出1个点，但我们的提示符生成方法进一步强调了两种方法的差异，使用Mine+Man方法的最高准确率相差4.2个点。这表明，如果有效地查询lm，高性能模型之间的差异可能会变得更清楚。KnowBert在LAMA上的表现不如BERT，

![image-20230925104726884](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925104726884.png)

#### LAMA-UHN Evaluation

LAMA-UHN基准测试的性能如表9所示。尽管总体性能与原始LAMA基准上的性能相比大幅下降(表2)，但优化后的集成仍然可以大大超过手动提示，这表明我们的方法在检索不能基于表面形式推断的知识方面是有效的。

![image-20230925104912457](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925104912457.png)

#### Performance on Google-RE

我们还在表10中报告了优化后的集成在GoogleRE子集上的性能。再一次，集合不同的提示提高了BERT-base模型和BERT-large模型的准确性。这种增益比T-REx子集上的略小，这可能是由于只有3个关系，其中一个(预测一个人的出生日期)特别难，以至于只有一个提示的准确性是非零的。

![image-20230925105015952](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925105015952.png)

### Analysis

#### 提示预测一致性

我们首先分析提示符产生不同预测的条件。我们使用以下公式定义两个提示符tr,i和tr,j的预测之间的散度:

![image-20230925105139207](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925105139207.png)

其中C(x, y, tr,i)如果提示tri= 1，则可以成功预测y，否则为0。对于每个关系，我们将两个提示符的编辑距离归一化为[0,1]，并将归一化的距离分成5个桶，间隔为0.2。在图3中，我们为每个箱子绘制了一个框图，以可视化预测发散的分布，绿色三角形代表平均值，框中的绿色条形图代表中值。当编辑距离变大时，分歧也会增加，这证实了我们的直觉，即**非常不同的提示往往会导致不同的预测结果**。Pearson相关系数为0.25，说明这两个量之间的相关性较弱。

![image-20230925105514890](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925105514890.png)

#### POS-based Analysis

我们尝试通过分析从lm中成功提取知识的词性模式来研究哪种类型的提示在抽象中更有效。

ReVerb (Fader et al.， 2011)引入了表11中列出的三个句法约束，以提高挖掘出的关系短语的连贯性和信息量。

![image-20230925110516363](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925110516363.png)

为了测试这些模式是否也表明了提示从lm检索知识的能力，我们**使用这三种模式将方法生成的提示分组为四个集群，其中“其他”集群包含不匹配任何模式的提示**。然后我们计算每个提示符在提取出来的提示符中的等级，并使用图4中的框线图来绘制等级分布。我们可以看到，匹配这些模式的提示符的平均等级要高于“其他”组的提示符，证实了我们的直觉，好的提示符应该符合这些模式。

![image-20230925110850153](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925110850153.png)

#### 跨模型一致性

我们正在提取的提示符是否高度定制于特定的模型，或者它们是否可以跨模型泛化。为此，我们使用了两种设置:一种是**比较BERT-base和BERT-large**，相同的模型结构，但大小不同;另一个比较了**BERT-base和ERNIE**，不同的模型体系结构具有相当的规模。

如表12和表13所示，我们发现在跨模型场景下(第三列和第五列)通常会有一些性能下降，但损失往往较小，实际上查询BERT-base时的最高性能是通过在BERT-large上优化的权值实现的。值得注意的是，在另一个模型上，权重优化后的最优准确率为40.1%和42.2%(表12)，最优准确率为39.5%和40.5%(表13)，仍然远高于人工提示，说明优化后的提示在模型间仍然具有较大的增益。

![image-20230925111543623](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925111543623.png)

使用基于BERT-base优化的权重时，ERNIE(表13中的最后两列)的性能下降比BERTlarge(表12中的最后两列)的性能下降更大，这表明共享相同架构的模型从相同的提示符中获益更多。

#### Linear vs. Log-linear Combination

我们在主要实验中使用对数线性概率组合。然而，也可以通过正则线性插值来计算概率:

![image-20230925111622650](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925111622650.png)

在图5中，我们比较了这两种结合来自多个挖掘出的提示符的预测的方法。我们假设对数线性组合的表现优于线性组合，因为对数概率使得惩罚在任何特定提示下非常不可能出现的对象成为可能。

![image-20230925111718979](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230925111718979.png)

## Conclusion

在本文中，我们研究了从语言模型中检索事实知识时使用的提示的重要性。我们**提出了基于挖掘和释义的方法**，**系统地生成不同的提示来查询特定的关系知识片段**。当这些提示符组合在一起时，事实知识检索的准确性提高了8%，大大超过了手工设计的提示符。我们的分析表明，lm确实比之前的结果显示的更有见识，但它们对我们如何查询它们也相当敏感。这表明了未来可能的方向，如(1)**更健壮的lm**，可以用不同的方式查询但仍然返回类似的结果，(2)将事实知识纳入lm的方法，(3)进一步优化查询lm的方法以获取知识。