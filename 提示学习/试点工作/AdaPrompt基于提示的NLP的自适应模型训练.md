# AdaPrompt:基于提示的NLP的自适应模型训练

## https://github.com/cylnlp/AdaPrompt 项目代码

## Abstract

基于提示学习能够有效地处理零样本和少样本的自然语言处理任务，受到了社会的广泛关注。

主要思想是通过**将这些任务映射为自然语言提示**，然后**由预先训练的语言模型(PLMs)填充**，来弥合NLP下游任务和语言建模(LM)之间的差距。

然而，对于提示学习来说，NLP任务和前训练之间仍然存在两个显著的差距。首先，**在LM的培训前，提示信息不一定充分呈现**。第二，**在训练前，特定任务的数据不一定能很好地表现出来**。

为了解决这两个问题，我们提出了**AdaPrompt**，**利用任务和提示特征自适应检索外部数据**，**用于plm的持续预训练**。此外，我们利用自然语言推理模型中的知识来推导自适应语言器。在5个NLP基准上的实验结果表明，AdaPrompt在少样本情况下比标准PLMs有更好的性能。此外，在零样本设置下，我们的方法比基于标准提示的方法的相对误差降低了26.35%。

## Introduction

基于提示的方法(Brown等人，2020年;Liu等人，2021年;Schick and Schütze, 2021a;近年来，自然语言处理(NLP)受到越来越多的关注。其主要思想是通过将**NLP任务调整为自然语言提示**，从而**最大限度地利用预训练语言模型(PLMs)，然后由PLMs填充自然语言提示**。以情感分类为例(Socher et al.， 2013;Bai等人，2021年)。给出这句话“我喜欢这部电影。，标准任务是对其情绪极性(即积极或消极)进行二元分类。

基于提示的方法首先把句子转换成“我喜欢这部电影。<u>电影是<mask></u>。(带下划线的文本称为prompt)，然后通过检查plm是否倾向于预测<mask>令牌的“好”或“坏”来确定其极性(预测的单词随后被表达成类标签)。

基于提示的任务公式接近于蒙面语言建模(Schick和Schütze, 2021a,b)，这是主流的前训练策略，允许plm无缝提供丰富的语言知识。基于提示的方法已被证明在零样本和少样本设置中特别有用(Petroni et al.， 2019;Yin et al.， 2019;Min等人，2022)，在直接任务数据有限的情况下，基于提示的推理比面向任务的微调更能从大规模的预训练中获益

然而，现有的方法仍然存在一些潜在的限制。首先，用于预训练的大型原始文本数据**并不一定包含与特定任务提示直接相关的足够的模式**.

![image-20230918112610549](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918112610549.png)

一个问题分类任务的提示是“您能告诉我<mask>:What are the twin cities?”，其中<mask>应该是一个类标签词，例如，位置，人等(此示例的正确标签是定义)。

LM的训练前数据通常是**图书语料库**(Zhu et al.， 2015)加上**维基百科语料库**，这样的提示**几乎不会以文字或转述的形式出现**。因此，直接使用plm来填充跨域的手工提示可能会**导致性能低下**。第二，**将标签词项目到任务标签**，现有的大部分工作(Schick和Schütze, 2021a,b;Cui等人，2021)使用了一个预定义的词库。然而，它通常需要专业知识来构建一个可以彻底覆盖候选词的语言表达器，一个设计糟糕的语言表达器会**限制预测的准确性**。

我们提出了**AdaPrompt**，这是一个**考虑到提示符和语言表达器的框架**，使plm适应最终任务。我们感兴趣的是在零样本设置下解决上述问题，其中很少或没有标记的训练数据可用于特定任务。其主要思想是，通过从原始输入数据中探索知识，使PLM适应一个强大的基于提示的最终任务模型。

![image-20230918113612155](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918113612155.png)

如图2所示，给定一个没有标签的原始测试集，我们首先要求PLM为每个输入填充一个提示模板(例如，“总的来说，电影很棒。，而“伟大”则被plm填满了)。然后，我们使用结果文本(输入文本+提示+ PLM输出)作为提示感知查询，从大型无标记语料库中检索相关数据。通过这种方式，我们可以**获得一个既包含任务特征又包含提示特征的大数据集，并对检索到的数据进行自适应连续预训练**(Gururangan et al.， 2020)对PLM进行预训练，这可以极大地有利于基于提示的方法处理下游的NLP任务。

同时，我们发现目前构建言语者的方式也不是最优的。给定一个特定的任务，**不同的单词可以被表达成相同的类标签**。例如，大量的形容词可以表达积极的情绪，表现最好的候选人取决于领域、PLM和上下文。

在AdaPrompt中，我们提出**利用plm和自然语言推理(NLI)模型中的知识自适应地扩充语言器**。以情感分析为例，假设“good”和“bad”作为种子谓词，我们首先让PLMs预测更多的候选词，如“amazing”和“great”。然后，为了确定这些候选人是否适合使用语言，我们参考NLI模型来预测“This movie is amazing.”包含着“这部电影很好”的意思。通过这种方式，我们可以自动扩展语言表达器。

## Related work

### Zero/Few-shot Prompt-based NLP

现有的工作主要集中在文本分类上,一个典型的相关工作是**PET** (Schick和Schütze, 2021a)，其中Schick和Schütze (2021a)正式定义了模式-语言表达器对，并被后续的作品广泛采用。通过使用这些对，Schick和Schütze (2021a,b)开展了一系列工作来探索plm的潜力，包括为原始训练数据标注软标签，以及迭代地进行数据增强。

然而，与假定下游任务有大量的银色训练集可用不同，我们关注的是零和非常少的镜头设置，在这些设置中，即使没有注释的任务相关数据集也是有限的(Perez et al.， 2021)。因此，在Hu等人(2022)之后，我们**只关注用于文本分类的标准模式词汇分析器对**

提示工程(Jiang et al.， 2020;Gao等人，2021)的重点是**如何创建能够更好地诱导plm做出正确预测的提示**。离散提示语工程通过**替换、删除、插入或转述部分提示语**来实现.这些方法可以有效地**使plm适应结束任务**，但它们**高度依赖带注释的数据来调优参数**。与上述研究不同的是，我们**感兴趣的是缩小LM前训练任务和NLP任务之间的差距**，以促进学习在零或非常少的镜头设置。

已经证明使用不同的语言器也可以是提示学习的一个关键因素.我们专注于探索plm本身的知识。利用外部NLI模型，AdaPrompt可以自动选择语言器，而不需要带标签的任务数据，这在零样本设置中非常有用。

### Continual Pretraining for Domain Adaptation(持续的领域适应预训练)

持续的预训练(Gururangan et al.， 2020)显示了在进一步微调之前将PLM优化到目标域的好处。

它可分为**领域自适应持续预训练和任务自适应持续预训练**。不同的是，领域自适应预训练(DAPT)使用的是**领域相关数据**，而任务自适应预训练(TAPT)使用的是**任务相关数据**。

数据选择是NLP模型领域自适应的一种常见实践,它已被用于机器翻译 解析和情感分析.主要思想是有一个可以区分域内和域外数据的选择模型。

选择模型可以是一个**监督分类器**(Aharoni和Goldberg, 2020)，**基于相似度的度量**(Plank和van nord, 2011)或语**言模型困惑**(Moore和Lewis, 2010)。Yao等人(2021)提出从通用语料库中检索一小组训练数据，将有标记的任务数据作为查询，发现在该数据上使用LM目标作为辅助损失，可以帮助训练任务特定的NLP模型，而无需进行前训练。

## Method

我们的方法是基于提示符的文本分类方法,

### Prompt-based Text Classification

给定一个输入文本，x = (x0, x1，…， xn)，我们考虑各种任务将句子分类为类标签l∈L。标准的基于提示符的方法将输入**重新定义为完形问句**，并通过检查plm的预测来识别其标签。

![image-20230918161225771](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918161225771.png)

这些数据集涵盖了情感分类、主题分类和问题分类任务。形式上，让M是在大规模通用数据上预训练的语言模型，<mask>为掩码令牌。基于提示符的方法首先**定义了一个模式函数Prompt**，该函数将x转换为包含<mask>的完形问题。然后，定义一个词词函数v，将<mask>位置预测的一小组预定义词词(Y)映射到类标签中，即v: Y I→L。

以电影评论的情感分类为例。任务是对情绪极性进行分类，其中L ={正，负}。对于输入x，我们选择如下模式:

![image-20230918161640194](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918161640194.png)

![image-20230918162213606](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918162213606.png)

### Adaptively Retrieve Data for Continual Pretraining(自适应检索持续预训练数据)

缺乏领域适应可能是基于提示的NLP模型的一个潜在挑战，特别是在零样本和非常少镜头设置下。

为了解决这一问题，我们提出**从通用语料库中检索测试文本、设计提示和标注单词作为查询的连续训练数据集**。通过这种方式，我们可以仅使用测试输入就获得任何任务或域的任务相关数据。同时，在检索过程中也考虑了提示信息和语言信息，从而为提示词的持续预训练提供了更全面的数据集。

在形式上，给定一个检索查询q，在一个大型通用数据集D上建立索引的检索引擎εD可以返回一组类似的文本dq = εD(q)。

为了获得不仅能使plm适应目标域，还能使plm对提示更加敏感的提示感知数据，我们在构建查询时同时**包含了任务和提示特征。**

对于文本数据中的原始输入文本x，我们首先将其转换为Prompt(x)，然后使用PLMM获得一组预测的标签词:

![image-20230918163604728](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918163604728.png)

其中O = {o1, o2，…， o| o|}是top|O|的预测。我们用oi替换P(x)中的掩码令牌，以形成一个查询列表Q。例如:

![image-20230918163742042](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918163742042.png)

其中qi = “x. In summary, the movie is oi.

使用这组基于提示的查询，我们检索提示感知数据Dp，它是一般数据的一个小子集。在本工作中，我们使用在大型通用语料库上建立索引的ElasticSearch作为搜索引擎，并要求它返回匹配查询的top-k文本列表。

一个测试输入可以导致多个感知提示的查询，因为提示中的蒙面令牌可以被|O|预测替换。此外，给定一个查询，ElasticSearch还可以使用要求的k给出多个返回值。

继续用掩蔽语言建模损失对PLM在Dp上进行预训练，得到一个适应性的PLM MDp。MDp现在包含更丰富的目标域和提示符的知识。它可以代替式1中的M进行零样本文本分类

### Iterative Adaptation

在获得MDp后，我们可以通过将公式3中的**M替换为MDp**来迭代该过程，得到预测单词的迭代集和标记为O'和Q'的查询列表。

考虑到O包含更多的领域内知识，我们可以检索到更多任务相关信息的更高质量的训练前数据，使用Q查询ED。这样，我们得到了一个新的Dp版本，以及一个新的连续预训练的PLM M'Dp，

### Adaptive Verbalizer Augmentation

常规的基于提示的方法定义了将预测的标签词映射到任务类的语言表达器，例如“好”表示积极，“坏”表示消极。但是，预定义的语言表达器可能是有限的。为了扩展这个表达器，我们首先**在测试集中所有输入的掩码标记位置推断top- |o |标记单词。我们过滤预测的词，并获得一组高频率的词C作为候选词**。然后，我们提出了一种新的方法，利**用自然语言蕴涵模型中的知识来挖掘有用的词汇。**

给定标签l的种子语言表达器yl∈yl，以及候选词c∈c，我们比较由yl填充的提示符是否包含由c填充的提示符。

![image-20230918171424558](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918171424558.png)

如果这一对的蕴涵关系成立，我们在Yl上加上c add，而新的Y可以被认为是一个扩充的语言表达器。

在得到语言表达器的增广集后,可以将式1改写为

![image-20230919094938223](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919094938223.png)

## Experiments

### Datasets and Prompts

为了评估我们的方法，我们在五个基准上进行了实验:**SST-2** (Socher et al.， 2013)， **Yelp** (Zhang et al.， 2015)， **AGNews** (Zhang et al.， 2015)， **TREC** (Voorhees and Tice, 2000)和**DBPedia** (Lehmann et al.， 2015)数据集。![image-20230919095519917](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919095519917.png)

表1显示了我们为每个数据集使用的提示模板和种子表达器单词。对于AGNews和YELP，我们采用了PET (Schick和Schütze, 2021a)中的模式和动词，因为它是基于提示的基本方法，已经被广泛使用。

1. AGNews是News领域的一个文本分类数据集。给定标题和正文，模型需要将新闻分类为(1)世界，(2)体育，(3)商业或(4)科学/技术。
2. YELP是一个情绪分析数据集。给定一份餐厅评论，任务是预测该评论是正面还是负面。
3. SST-2是一个类似于YELP的情感分析数据集，但它的研究领域是电影评论。因此，我们使用与YELP相同的种子提示和言语词，但将提示模板中的“restaurant”改为“movie”。
4. DBPedia 2014是一个本体分类数据集，提取自DBPedia 2014，包含14个非重叠类，如Educational Institution和Office Holder。我们为这个任务定义了两个模式:(1)P1(x) = “Description to the <mask> x”(2)P2(x) = “Introduction to the <mask> x”使用P2作为种子模式。
5. TREC-10是一个问题分类数据集。给定一个问题，任务是确定问题提出的目标，并将其分为六类之一，如定义问题或数字问题。我们为这个任务定义了两个模式:(1)P1(x) = “Tell me the <mask> x”(2)P2(x) = “Can you tell me the <mask>: x”,使用P2作为种子模式

### Settings

我们将**ROBERTA-large** (Liu et al.， 2019)作为我们的基础PLM，并采用来自(Schick和Schütze, 2021a)的**模式语言分析器对作为基线设置**，该设置被广泛使用，并且可以很容易地扩展到其他方法

我们进行了零样本和少样本设置的实验。在零样本设置中，我们**直接使用PLMs在掩码位置推断标签词**。在少样本设置下，我们跟踪Schick和Schutze (2021a)和Hu等人(2022)，并**使用提示调优**，它直接微调LM，给定一小组带注释的数据和提示。

对于零样本设置，超参数的选择是基于以前的工作(Gao et al.， 2021;Schick和Schütze, 2021a,b)。对于所有持续的预训练，我们使用1e - 5的学习速率，批量大小为96。我们对每个模型进行3个阶段的训练，并使用500步的检查点进行评估。

对于少样本设置，我们用10,50,100个训练样本来评估我们的模型。我们继续之前的工作(Hu et al.， 2022;Schick and Schütze, 2021a;Gao et al.， 2021)，并**使用不同的种子重复训练和评估5次**，并报告每个数据集的平均分数。

#### Prompt-Aware Data Retrieval(提示感知数据检索)

我们将ROBERTA模型(BOOKCORPUS (Zhu et al.， 2015)、WIKIPEDIA、CCNEWS (Nagel, 2016)、STORIES (Trinh and Le, 2018)和OPENWEBTEXT (Gokaslan and Cohen, 2019)的训练前数据作为查询的通用数据集。我们使用**ElasticSearch在句子级别对它们进行索引**，并将**TF-IDF作为相似度度量**。

表2给出了本文使用的评估数据集的统计数据。TREC和SST包含较小的测试集，而YELP和DBPedia包含更大的测试集。为了平衡检索到的数据量，我们根据实践经验为预测词设置了不同的top-|O|，并为不同的数据集设置了ElasticSearch空间(k)。换句话说，给定一个测试输入，我们有|o | × k数据。重复数据删除后，检索到的数据大小如表2所示。

![image-20230919102238160](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919102238160.png)

#### Verbalizer Augmentation

为了获得能够更好地表示类的可能的表达器，我们首先**获得给定一个测试样本的top-N预测词**(SST-2和TREC的预测词数为20,AGNews的预测词数为10,YELP和DBPedia的预测词数为5，考虑到它们的测试集大小)。

设候选词|C| = 20 × |L|，其中|L|为类数。我们使用了一个在**MNLI上经过微调的roberta大型模型**(Williams等人，2018)，作为隐含模型，用于识别潜在的用于增强的语言词。

将概率高于阈值t的候选对象添加到增强的语言表达器中。我们通过实验设定t = 0.4。

为了进行比较，我们还使用**Word2Vec** (Mikolov et al.， 2013)**来获取词向量**，并通过它们与种子词库词的相似性来探索潜在的词库词。

### Results

#### Main Results

##### Zero-shot Performance

在零样本设置下，我们分别使用**ROBERTA** (Schick and Schutze, 2021a)、**GPT-2** (Gao et al.， 2021)和**GPT-3** (Zhao et al.， 2021)比较**AdaPrompt和基于prompt**的方法。**Channel**是基于GPT2的噪声信道模型

表3给出了零样本集的结果。在之前的工作(Schick和Schütze, 2021a,b)之后，我们报告了**不同模式下最佳模式的平均精度、标准差和准确性。**

![image-20230919102723168](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919102723168.png)

r代表ROBERTAlarge。Ada和iAda分别表示AdaPrompt和基于ROBERTA-large的迭代AdaPrompt。

与我们的基础模型ROBERTA-large相比，我们发现AdaPrompt在所有数据集上始终优于基于提示的常规方法，具有更好的平均性能和最佳模式性能，带来了2.46 ~ 14.63的改进。值得注意的是，AdaPrompt在零样本设置方面优于GPT-3, GPT-3是一个巨大的模型，在一个巨大的语料库上预先训练了175B参数。这证实了AdaPrompt在域适配中的有效性。

**迭代AdaPrompt可以进一步改进大多数数据集**(SST-2, YELP和DBPedia)。这直接说明，**plm对检索到的数据进行持续的预训练，可以更适应下游任务，从而生成更多与任务相关的标签词**，这些标签词可以作为查找更好文本的来源。

##### Few-shot Performance

表4给出了在少镜头设定下的实验结果。每个实验使用不同的种子重复5次，我们报告平均准确度和标准偏差。为了探究AdaPrompt是否能够持续地给ROBERTA带来改善，我们分别用**10个、50个、100个样本**进行了实验。

表4给出了在少镜头设定下的实验结果。每个实验使用不同的种子重复5次，我们报告平均准确度和标准偏差。为了探究AdaPrompt是否能够持续地给ROBERTA带来改善，我们分别用10个、50个、100个样本进行了实验。

![image-20230919103738292](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919103738292.png)

与ROBERTA-large基线相比，在少样本设置下，AdaPrompt仍然可以提高模型性能。虽然随着训练集大小的增加，相对的改进有所减少，但是我们可以看到AdaPrompt在所有少样本设置下的所有任务上都优于ROBERTA。特别是，AdaPrompt在10拍的情况下比标准ROBERTA模型的表现好2.29 ~ 5.79%，表明它在很少拍的情况下是有用的。

#### Ablation Study

为了研究持续预训练对提示意识数据和言语增强的效果，我们进行了**去除持续预训练(CP)或言语增强(va)的消融实验。**

由表5可知，与基础模型(-CP-va, 61.71 acc 平均而言)，持续的前训练和语言增强都能带来模型性能的改善(5.31和5.89 acc)，两种方法结合使用(AdaPrompt)时，模型效果最好，说明两种方法可以相互受益。

我们研究了去除提示感知检索和仅使用原始文本检索对模型性能的影响。从表中我们可以看到，在所有的数据集上，使用**提示增强查询(AdaPrompt)可以得到更强的结果**。以SST-2为例，仅在原始输入查询时，准确率为**71.22** (SST-2 -PR)，而在提示增强查询时准确率为**75.92**，绝对提高了4.7。这表明，**使用提示感知数据的持续预训练对基于零样本提示的NLP非常有利。**

### Analysis

#### Generalization Capability

我们使用任务测试集作为数据源来构建查询来检索训练前数据。但是，在更一般的设置中，我们**想了解当查询数据和测试集不同时，AdaPrompt是否仍然可以泛化到这个测试集**。

为此，我们利用SST-2和DBPedia的原始训练集构建了一个**看不见的测试集**。然后我们对这个不可见的测试集评估模型(**使用来自原始测试集的查询进行训练**)。

![image-20230919105235484](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919105235484.png)

AdaPrompt在SST-2和DBPedia上的准确率分别为73.05和70.97。与原始测试集的性能相比(表3)，虽然AdaPrompt在**SST-2看不见的测试集上的性能略有下降**，但仍然可以大大超过ROBERTA(+8.23)。结果表明，当查询数据和测试集不同时，AdaPrompt具有较强的泛化能力。

#### Size of Retrieved Data

Elasticsearch**按照匹配分数的顺序返回top-k文本**。使用较小的k时，**检索到的数据与查询相关的文本更多**，而使用较大的k时，**检索到的数据可能包含一定的噪声**。为了比较不同大小的检索数据对持续预训练的影响，我们将SST-2的k设置为1、10、50 100,DBPedia的k设置为1、5、25、50。

![image-20230919105548764](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919105548764.png)

可以看到随着检索大小的增加，准确率在一开始就有所提高。但随着检索规模的增大，准确率开始略有下降。这可以解释为，**检索的数据等级越低，与目标任务的相关性越低，在持续的预训练中引入更多的噪声**。

由于缺少验证集，我们在零样本设置中使用fixed k进行实验,在少样本设置中，在实践中，k可以被视为超参数，并在验证数据之上进行调优。

#### The Effect of Verbalizer Strategies

表8比较了使用不同的词汇增强策略时的模型性能，即使用NLI模型和单词相似度(4.2节)。此外，我们将AdaPrompt与使用知识库(KB)的一种语言增强方法进行了比较(Hu等人，2022)。为了进行公平的比较，我们将每个标签的词集限制在5个以内。我们在这里报告平均精度和标准偏差。

![image-20230919110225095](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919110225095.png)

结果表明，与使用词相似度来选择候选词和直接使用KBs来增加词量相比，使用NLI来增加词量在大多数任务上有更好的性能，也更稳定。我们还发现，使用KBs来增加词汇量可以在DBPedia任务上获得更好的性能，但在TREC任务上的性能要差得多。这可能是因为TREC不太接近主题分类,直接使用最相关的词可能会有噪声。这也表明，**更复杂的策略，关注任务和及时的信息可能是有用的**，我们把这留给未来的工作。

#### AdaPrompt with different PLMs

我们将AdaPrompt应用于不同的plm (Bert-large, Albert-large和ROBERTA-large)。我们在表9中报告了SST-2数据集的实验结果。虽然不同模型的性能不同，但我们观察到AdaPrompt可以持续地给所有模型带来巨大的改进。我们还发现模型性能随模型尺寸的增大而增大。使用ROBERTA-large的AdaPrompt在总体性能上大大超过其他模型(8.29 ~ 18.67)，在最佳模式下达到了91.74的准确度。

![image-20230919111502535](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230919111502535.png)

## Conclusion

我们研究了AdaPrompt，一种基于零样本提示的NLP方法，它利用测试输入数据和提示进行自适应的连续预训练和语言器选择。在五个分类数据集上的结果表明，AdaPrompt比标准提示方法有很大的改进。特别是，检索相关数据进行语言模型的持续预训练，可以为该模型的领域适应和即时填充任务做好准备。此外，NLI模型允许有效地选择填充令牌来实现改进的性能。

### 缺陷

1. 我们只测试了ElasticSearch作为搜索方法。然而，有迹象表明，检索到的文本质量受到搜索引擎的限制。搜索方法的更好配置或模型可能会进一步改进AdaPrompt。
2. 我们只在文本分类任务上测试AdaPrompt。其目的是利用这种清晰的设置与其他基于提示的模型进行比较。然而，我们可以将AdaPrompt扩展到其他自然语言理解任务或语言，这将留给未来的探索。