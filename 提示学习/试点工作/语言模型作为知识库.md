# 语言模型作为知识库?

## Abstract

基于大型文本语料库的语言训练前模型的最新进展导致了下游NLP任务的大幅改进。在学习语言知识的同时，这些模型也可能存储存在于训练数据中的关系知识，并可能能够回答结构化为“填空”完形语句的查询。

与结构化的知识库相比，语言模型有很多优势:它们**不需要模式工程**，允许实践者查询一个开放类的关系，很容易扩展到更多的数据，并且**不需要人工监督来训练**。

我们提出了一个深入的分析关系知识已经存在(没有微调)在广泛的最新的预先训练的语言模型。我们发现(i)在没有微调的情况下，BERT包含的关系知识与传统的NLP方法相比具有一定的oracle知识，(ii) BERT在开放式领域的问题回答上也表现得非常好，(iii)通过标准语言模型前训练方法，某些类型的事实知识比其他类型的知识更容易学习。这些模型在不进行任何微调的情况下回忆事实知识的惊人强大能力证明了它们作为无监督开放领域QA系统的潜力。

## Introduction

经过预训练的高容量语言模型，如ELMo (Peters et al.， 2018a)和BERT (Devlin et al.， 2018a)在自然语言处理中变得越来越重要。它们被优化为**要么预测序列中的下一个词**，要么**预测给定序列中任何地方的某个蒙面词**(例如:“但丁在1265年出生在[MASK]。”)。

这些知识通常是通过对原始模型产生的潜在上下文表示的条件设置来获取的，或者是通过使用原始模型权值来初始化一个特定于任务的模型，然后对该模型进行进一步的微调。这种类型的知识转移对于当前各种任务的最先进的结果是至关重要的。

**知识库**是访问带注释的金标准关系数据的有效解决方案，它支持诸如(Dante, born-in, X)这样的查询。然而，在实践中，我们经常需要从文本或其他形式中提取关系数据来填充这些知识库。这需要复杂的NLP管道，包括实体提取、共引用解析、实体链接和关系提取,这些组件通常需要监督数据和固定模式。此外，错误很容易在整个管道中传播和积累。

我们引入了**语言模型分析**(LAMA)探针，它由一组知识来源组成，每个知识来源由一组事实组成。我们定义一个预先训练的语言模型知道一个事实(主语、关系、宾语).如果它能成功地预测完形填空句子中的蒙面对象来表达这个事实

我们的调查显示(i) Devlin等人(2018b) (BERT-large)的最大BERT模型捕获的(准确的)关系知识，可与使用现成的关系提取器和基于oracle的实体链接器从已知的表达相关知识的语料库中提取的知识库相媲美，(ii)事实知识可以很好地从训练前的语言模型中恢复，然而，对于某些关系(特别是n - m关系)表现非常差，(3) BERT-large在恢复事实和常识知识方面一直优于其他语言模型，同时对查询的语法更加健壮，(4)BERT-large在开放领域QA中取得了显著的结果。达到57.1% precision@10，而使用特定任务的监督关系抽取系统构建的知识库占63.5%。

## Background

### Unidirectional Language Models

给定一个符号输入序列w = [w1, w2，…，单向语言模型通常通过如下分解将概率p(w)赋给序列

![image-20230917111542139](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230917111542139.png)

估计这种概率的一种常见方法是使用神经语言模型

![image-20230917111650924](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230917111650924.png)

ht∈Rk是位置t处的神经网络的输出向量，W∈R|V| × k是一个已学习的参数矩阵，它将ht映射到词汇V中每个单词的未归一化得分。

#### fairseq-fconv

Dauphin等人(2017)使用多层门控卷积，而不是常用的递归神经网络。我们在研究中使用fairseq库中的预训练模型。它在Merity等人(2016)引入的wikitext -103语料库上进行了训练。

#### Transformer-XL

Dai等人(2019)引入了基于Transformer的大规模语言模型(Vaswani等人，2017)。Transformer-XL可以缓存以前的输出，并使用相对而不是绝对位置编码，从而考虑到更长的历史。在WikiText-103语料库上获得了18.3的测试困惑度。

### Bidirectional “Language Models

我们已经研究了在给定单词历史的情况下预测下一个单词的语言模型。然而，在许多下游应用程序中，我们主要关心的是**如何访问单词的上下文表示**，即，单词表示是一个文本单元(如句子或段落)的整个上下文的函数，而不仅仅是基于之前的单词。形式上，给定一个输入序列w = [w1, w2，…当位置1≤i≤N时，我们想估计p(wi) = p(wi | w1，…， wi−1,wi+1，…使用该词的左右上下文。

#### ELMo

为了估计这个概率，Peters等人(2018a)提出运行一个正向和向后的LSTM (Hochreiter和Schmidhuber, 1997)，得到→- hi和←- hi，它们因此被用来计算一个正向和向后的语言模型的对数似然。他们的模型ELMo使用了多层lstm

#### BERT

Devlin等人(2018a)提出在输入序列中随机取样位置，并学习在掩码位置填充单词，而不是标准的语言模型目标。还使用一个辅助的二元分类目标来预测一个特定的句子是否遵循给定的单词序列。

## Related Work

许多研究调查了预先训练的**单词表征、句子表征和语言模型**。现有的研究主要集中在**理解词汇表征的语言和语义属性**，以及如何**很好地训练句子表征和语言模型将语言知识转移到下游任务**。

我们的研究试图**通过将预先训练的语言模型与传统关系提取方法所填充的符号知识库进行比较**，来回答它们在多大程度上存储了事实和常识知识。

对于自然语言推理，基于BERT的模型会严重依赖易错的句法启发式，而不是对自然语言输入的更深入理解。Peters等人(2018b)发现ELMo中低层专门研究局部句法关系，而高层可以学习建模远程关系。同样，Goldberg(2019)发现BERT很好地捕捉了英语句法现象。

## The LAMA Probe

LAMA提供了一套由事实语料库组成的知识来源。事实要么是主题-关系-对象三元组，要么是问题-答案对。每个事实都被转换成一个**完形语句**，该语句用于**查询语言模型中缺失的标记**。我们根据**ground truth token**相对于固定候选词汇表中的其他单词的高度来评估每个模型。这类似于知识库完成文献中的基于排名的度量

### Knowledge Sources

为了在第2节中评估不同的语言模型，我们涵盖了**各种事实和常识知识的来源**。对于每个来源，我们描述了事实三元组(或问题答案对)的起源，如何将它们转换成完形填空模板，以及维基百科中已知的表达特定事实的对齐文本存在的程度。我们在监督基线中**使用后一种信息**，直接从对齐的文本中提取知识表示。

#### Google-RE

Google-RE语料库包含了从维基百科手工提取的约60K个事实。它包括五种关系，但我们只考虑其中的三种关系，即“出生地点”、“出生日期”和“死亡地点”。

#### T-REx

T-REx知识库是Wikidata三元组的一个子集。它来自T-REx数据集(Elsahar等人，2018)，比Google-RE大得多，具有更广泛的关系集。我们考虑了41个维基多关系和子样本，每个关系最多1000个事实。

##### ConceptNet

ConceptNet (Speer和Havasi, 2012)是一个多语言知识库，最初建立在开放思维常识(OMCS)句子之上。OMCS表示单词和/或短语之间的常识性关系。

#### SQuAD

SQuAD (Rajpurkar等人，2016)是一个流行的问题回答数据集。我们从SQuAD开发集中选择了305个上下文无关问题的子集，这些问题只有一个令牌答案。我们从这些问题中手工地创造完形问题，例如，重写“谁发展了相对论?”正如“相对论是由……发展起来的”。

### Models

考虑以下预先训练的案例敏感性语言模型(见表1):fairseq-fconv (Fs)、Transformer-XL large (Txl)、ELMo original (Eb)、ELMo 5.5B (E5B)、BERT-base (Bb)和BERT-large (Bl)。通过遵循训练目标函数的定义，我们使用自然的方式为每个模型生成标记。

![image-20230917114124960](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230917114124960.png)

假设我们想要计算位置t的令牌的生成。

1. 对于单向语言模型，我们在令牌之前使用网络输出(ht−1)来产生输出层softmax。
2. 对于ELMo，我们考虑前(→−h t−1)的输出，后(←−h t+1)的输出。按照(Peters等人，2018a)中的损失定义，我们对相应softmax层的前向和后向概率进行平均。
3. 对于BERT，我们将t位置的令牌进行掩码，并将对应于掩码令牌(ht)的输出向量输入到softmax层。

为了进行公平的比较，我们让模型在一个统一的词汇表上生成，这个词汇表是所有考虑过的模型的词汇表的交集(∼21K区分大小写的标记)

### Baselines

为了将语言模型与使用现成系统提取符号知识和回答问题的规范方法进行比较，我们考虑以下基线。

1. Freq:对于主语和关系对，这条基线**根据单词在测试数据中作为给定关系的对象出现的频率**对它们进行排序。它表示**总是针对特定关系预测相同对象的模型的性能上限**。
2. RE:考虑了Sorokin和Gurevych(2017)的预训练关系提取(RE)模型。该模型是在用维基百科关系标注的维基百科子语料库上训练的。
3. DrQA:Chen等人(2017)引入了DrQA，这是一个开放领域问答的流行系统。DrQA通过两个步骤来预测自然语言问题的答案。首先，使用TF/IDF信息检索步骤从大量文档(如Wikipedia)中查找相关文章。在检索到的前k篇文章中，一个神经阅读理解模型然后提取答案。

### Metrics

我们考虑**基于排名的度量**，并计算**每个关系的结果以及所有关系的平均值**。为了解释一个主题-关系对的多个有效对象(即，对于N-M关系)，我们遵循Bordes等人(2013)的方法，在测试时对训练数据中**除我们测试的对象之外的所有其他有效对象进行排序时，从候选对象中删除**。我们使用k (P@k)处的平均精度。对于给定的事实，如果该对象位于前k个结果中，则该值为1，否则为0。

### Considerations

在创建LAMA探针时，我们做了几个重要的设计决策。

对于每个关系，我们都**手动定义一个用于查询该关系中的对象槽位的模板**。

我们可以预期模板的选择会对结果产生影响，这确实是事实:对于某些关系，我们发现使用替代模板查询相同信息(与给定模型相关)的方法既差又好。我们认为，这意味着我们正在测量语言模型所知道的一个下界。我们将此论点与传统的知识库进行类比:传统知识库只有一种查询特定关系知识的方法，即使用该关系的关系id，这种方法用于测量其准确性。例如，如果关系ID是works-For，而用户要求的是is-working- For，那么KG的精度将为0。

我们只考虑单个令牌对象作为我们的预测目标。我们引入这一限制的原因是，多令牌解码增加了许多额外的可调参数(波束大小、候选评分权重、长度归一化、n-gram重复惩罚等)，这些参数模糊了我们试图测量的知识。

我们选择**只查询三元组中的对象槽**，而不是主题槽或关系槽。通过包含反向关系(例如contains和contained-by)，我们还可以查询主题槽。

我们考虑的模型是用不同的词汇表进行训练的。

## Results

![image-20230917142738422](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230917142738422.png)

### Google-RE

我们为每个关系使用标准完形填空模板查询lm。基本版和大版BERT模型的表现都大大优于其他所有模型。

### T-REx

Google-RE衍生的知识来源包含的事实相对较少，只有三种关系。因此，我们在T-REx身上进行更大范围的事实和关系的实验。我们发现结果与Google-RE基本一致。此外，BERT检索事实知识的性能与使用现成的关系抽取系统和基于oracle的实体链接自动构建知识库的性能接近。按关系类型细分，BERT的性能在1- 1关系(例如，大写)中非常高，而在n - m关系中则很低。

下游模型可以学习使用语言模型的输出表示中的知识，即使正确答案没有排在第一，但足够高(即，可以从输出表示中提取正确答案的提示)。

为了进一步研究BERT为什么能获得如此强的结果，我们计算了P@1和我们在图3中报告的一组度量之间的Pearson相关系数。例如，我们注意到一个对象在训练数据中被提到的次数与性能呈正相关，而对于一个关系的主体来说则不是这样。此外，预测的log概率与P@1呈强正相关。因此，当BERT对其预测有很高的信心时，它通常是正确的。性能还与主题和对象向量之间的余弦相似度呈正相关，与主题中的令牌数量略有相关。

![image-20230918105913602](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918105913602.png)

图4显示了每个事实10个查询的平均排名分布。两种BERT模型和ELMo 5.5B模型的变异性最低，而正确对象的平均排名接近最高。令人惊讶的是，ELMo原模型的性能与BERT相差无几，尽管该模型在训练过程中并没有看到Wikipedia。Fairseq-fconv和Transformer-XL的预测具有更高的可变性。请注意，BERT和ELMo 5.5B比fairseq-fconv和Transformer-XL在维基百科上接受了更多的训练，并且在训练过程中可能看到了更多包含测试查询的句子。

![image-20230918110236547](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230918110236547.png)

### 	ConceptNet

在ConceptNet语料库上的结果与在Google-RE和T-REx中检索事实知识的结果一致。BERT-large模型在检索常识知识和事实知识方面都具有较好的一致性。表3的下半部分显示了随机样本的BERT-large代。语言模型生成的一些概念除了语法正确之外，还非常合理。

### SQuAD

我们对我们的开放式完形问答系统进行了评估，并与有监督的DrQA模型进行了比较。表2显示了BERT-large和DrQA开放域QA系统在我们的完形任务上的性能差距。同样，请注意，预先训练的语言模型是完全无监督的，它没有经过微调，而且它没有访问专门的信息检索系统。此外，在P@10方面比较DrQA和BERT-large时，我们发现差距非常小(BERT-large为57.1,DrQA为63.5)。

## Conclusion

我们对公开可用的预先训练的语言模型中的事实知识和常识知识进行了系统的分析，发现**BERT-large**能够比其竞争对手更好地回忆这些知识，并在一个水平上显著地与非神经和监督的替代方法竞争。

了解我们常用的模型和学习算法捕获的数据的哪些方面是一个重要的研究领域，本文是对许多关注学习数据语言属性的研究的补充。

我们发现，从文本中提取知识库，其性能与直接使用预训练的BERT-large相当，这是不平凡的。尽管为我们的关系提取基线提供了可能表达目标事实的数据，从而减少了假阴性的可能性，并使用了一个慷慨的实体链接预言。由于BERT处理的数据量较大，我们怀疑它可能具有优势，因此我们将Wikitext-103作为附加数据添加到关系提取系统中，并观察到性能没有显著变化。这表明，**尽管随着数据的增加，关系提取的性能可能难以提高，但在不断增长的语料库上训练的语言模型可能在未来成为从文本中提取传统知识库的可行替代方案**

除了使用LAMA探针测试未来的预训练语言模型外，我们还对量化与不同自然语言模板相关的事实知识回忆的方差感兴趣。此外，对我们的评估设置来说，评估多个令牌答案仍然是一个公开的挑战。