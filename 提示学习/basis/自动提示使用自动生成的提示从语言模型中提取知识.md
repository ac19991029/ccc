# 自动提示:使用自动生成的提示从语言模型中提取知识

代码：http://ucinlp.github.io/autoprompt,

## Abstract

预训练语言模型的显著成功激发了对这些模型在预训练中学习何种知识的研究。**将任务重新定义为填空问题**(例如，完形填空测试)是衡量这类知识的一种自然方法，然而，它的使用受到编写适当提示所需的手工工作和猜测的限制。

为了解决这个问题，我们开发了**AUTOPROMPT**，这是一个自动方法，可以**基于梯度引导搜索**为不同的任务集创建提示符。通过使用AUTOPROMPT，我们发现蒙面语言模型(MLMs)具有执行情感分析和自然语言推理的内在能力，而不需要额外的参数或微调，有时可以达到与最近最先进的监督模型相当的性能。我们还表明，与LAMA基准上手工创建的提示相比，我们的提示可以从MLMs中引出更准确的事实知识，而且传销可以用作关系提取器，比监督关系提取模型更有效。

这些结果表明，自动生成的提示是现有探测方法的一种可行的无参数替代方法，随着经过训练的lm变得更加复杂和强大，可能会取代微调

## Introduction

经过训练的语言模型(LMs)在通过微调适应下游任务时取得了非凡的成功。前训练**提高了准确性**，但很难确定精细调优LMs包含的知识是在前训练还是在精细调优过程中学习的。

许多技术已经被提出，通过分析预先训练的lm的内部表示来引出这些知识。一种常见的策略是**使用探究式分类器**——利用lm的表示作为特征来预测某些属性的浅层分类器。然而，探测分类器需要额外的学习参数，因此容易出现**误报**;高探测精度并不是得出LM包含某一知识的充分条件

注意力可视化是另一种常见的技巧，也有类似的失败模式:注意力得分可能与潜在目标知识相关，但不是由潜在目标知识引起的，这导致人们批评将其用作解释

从这些模型中提取知识的一个更直接的方法是**提示**，因为它们毕竟是语言模型，也就是说，将任务转换为语言模型格式。与现有的模型分析方法相比，提示是无创的:它不引入大量的附加参数，也不需要直接检查模型的表示。

在本文中，我们引入autoprompt—为任何任务生成提示的自动化方法，如图1所示。

![image-20230927153810838](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20230927153810838.png)

给定一个任务，例如情感分析，AUTOPROMPT通过**根据模板将原始任务输入**(例如评论)**与一组触发令牌组合起来创建一个提示**。所有输入都使用**同一组触发令牌**，并使用Wallace等人(2019)**提出的基于梯度的搜索策略的变体来学习**。通过**边缘化一组相关的标签令牌**，将提示的LM预测转换为类概率，这些标记可以提前学习或指定，从而使LM的评估与任何其他分类器的评估相同

## Overview of AUTOPROMPT

从经过训练的lm中提取知识的一种自然方法是**将任务设置为填空问题**。

然而，编写提示不仅耗费时间，而且还不清楚相同的措辞是否对每个模型都有效，也不清楚是什么标准决定了特定的措辞是否最适合提取所需的信息。在此基础上，我们引入了AUTOPROMPT方法，该方法为特定的任务和感兴趣的MLMs构造定制的提示，使传销产生想要的知识图1提供了自动提示的说明。

这个提示符是**通过获取原始任务输入—一个或多个标记序列的集合—并使用模板将它们映射为标记序列来构造的。**

### Background and Notation

为了构造提示符，我们将原始的任务输入xinp(例如，图1中的回顾，“a real joy.”)与提示符xprompt(例如，“a real joy.”)区分开来。气氛很多对话克隆完全[面具]。”)，这是馈送到传销。

从xinp到xprompt的映射是使用**一个模板λ**完成的。这个模板定义了**每个输入序列在提示符中的位置**，以及**任何其他标记的位置**。特别是，它还**必须定义一个特殊的[MASK]令牌的放置，以便MLM填写(**在模板中由[P]表示，以区别于其他可能出现的[MASK]令牌)。将提示输入MLM产生一个概率分布p([MASK]|xprompt)，描述哪些令牌最有可能填入空白。

如果类标签自然地对应词汇表中的标记(例如，知识库完成任务中的实体名称)，那么这个分布可以很容易地解释为类标签上的分布。然而，对于诸如情绪分析之类的任务，可能有一组标签令牌Vy对应于一个特定的标签y。例如，在图1中，“Cris”、“marvelous”和“philanthrop”都表示积极的情绪。在这种情况下，类概率是通过边缘化一组标签令牌得到的:

![image-20231001110138579](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001110138579.png)

### Gradient-Based Prompt Search

提出了一种**自动提示语构建方法**。其思想是**添加许多“触发”令牌**，这些令牌在所有提示符之间共享(在图1的示例模板中由[T]表示)。这些令牌被初始化为[MASK]令牌，然后迭代地更新，以最大化批量示例的标签可能性

形式上，在每一步中，我们计算第j个触发令牌x(j) trig与另一个令牌w∈v交换所产生的对数可能性变化的一阶近似，然后我们确定估计导致最大增长的top-k令牌的候选集vcand:![image-20231001110411960](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001110411960.png)

其中win为w的输入嵌入，对x(j)trig函数的输入嵌入取梯度。请注意，计算这个候选集的开销与模型的单个前向传递和后向传递的开销大致相同(点积需要的乘法量与计算LM输出投影的乘法量相同)。对于集合中的每一个候选对象，我们在更新的提示符上重新计算公式(1)，并在下一步保留概率最高的提示符——这需要模型向前通过k次

### Automating Label Token Selection

在某些设置中，标签标记的选择是显而易见的(例如，当类标签直接对应词汇表中的单词时)，但对于涉及更抽象类标签的问题(例如，NLI)，什么标签标记是合适的就不那么清楚了。在本节中，我们将开发一种通用的两步方法来自动选择标签令牌Vy集。在第一步中，我们**训练一个逻辑分类器来预测类标签**，**使用上下文化的嵌入[MASK]令牌作为输入**:

![image-20231001110906720](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001110906720.png)

我们将这个分类器的输出写为:

![image-20231001110935592](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001110935592.png)

其中y和βy是标签y的学习权重和偏差项，i表示[MASK]标记的索引。

在第二步中，我们将h(i)替换为MLM输出的单词嵌入wout，得到得分s(y, w) = p(y|wout)。直观上，因为wout·h和y·h对于与特定上下文相关的单词和标签来说比较大，所以sw∝exp(wout·y+βy)对于通常与给定标签相关的单词应该比较大。然后由k值最高的评分词构建标签令牌集:

![image-20231001111200811](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001111200811.png)

## Sentiment Analysis

使用我们的方法，使用标准的训练/测试分割，将实例从**二进制的Stanford Sentiment Treebank** (Socher et al.， 2013, SST-2)**转换为提示符**。

![image-20231001111624171](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001111624171.png)

对于基于梯度的提示符搜索，我们对以下超参数执行网格搜索:|Vcand|∈{10,100}，|Vy|∈{1,3,5}，|xtrig|∈[3,6]所有提示都使用用于查找标签集的相同模板进行初始化。

![image-20231001111909583](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001111909583.png)

## Natural Language Inference

我们使用来自**SICK数据集**(Marelli et al.， 2014, SICK- e)的蕴含任务，该任务由大约10,000对标注为蕴含、矛盾和中性的人类注释句子组成。标准数据集偏向于代表56.7%实例的中立类。我们还对一个无偏变量进行了实验，该变量包含矛盾与蕴涵的双向分类(2-way)，以及一个无偏3-way分类变量(3-way)。用于自动提示的模板如表3所示。我们搜索如下参数:|Vcand|∈{10,50}，|Vy|∈{1,3,5,10}，|xtrig|∈[1,5]，并根据开发集精度选择最佳提示符。

![image-20231001112316013](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001112316013.png)

## Fact Retrieval

LAMA数据集(Petroni等人，2019)使用完形填空测试来评估这个问题，该完形填空测试由(sub, rel, obj)三元组组成，例如(Obama, bornIn, Hawaii)，并手动创建缺少对象的提示，例如“Obama was born in [MASK].”。

我们使用相同的完形格式设置，但会自动生成提示，以便更好地评估MLMs的事实知识。我们将我们的方法与LAMA和LPAQA进行比较，这两种方法都是为事实检索任务而设计的。

我们通过使用模板“{sub}[T]. .[T] [P]”将(sub,rel,obj)三元组映射到提示符来重新规划事实检索。其中触发令牌特定于关系rel，正确的对象obj是标签令牌。我们使用LAMA数据集

使用带有5或7个标记的AUTOPROMPT，并使用T-REx开发集选择搜索参数。我们防止在训练数据中作为金对象出现的专有名词和令牌被选择为触发令牌。这样做是为了防止自动提示符通过在提示符中嵌入常见的答案而“作弊”。为了评估，我们观察传送带标签令牌分配中真实对象的等级，并使用标准的排名指标:平均倒数等级(MRR)、精度-at-1 (P@1)和精度-at-10 (P@10)

![image-20231001113053541](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001113053541.png)

## Relation Extraction

使用关系抽取(RE)任务来确定给定句子中的实体是如何关联的，其中触发器令牌是特定于关系的，而标签令牌是正确的对象obj

将T-Rex数据集用于RE，因为每个T-Rex事实都带有提到主语和宾语表面形式的上下文句子。我们比较了AUTOPROMPT与LAMA和LPAQA以及Petroni等人(2019)也使用的最近的监督关系抽取模型

![image-20231001113550417](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231001113550417.png)

## Conclusion

介绍了AUTOPROMPT，一种开发自动构造的提示符的方法，该提示符从预训练的mlm中引出针对各种任务的知识。我们表明，这些提示比手工提示更有效，同时需要更少的人力。