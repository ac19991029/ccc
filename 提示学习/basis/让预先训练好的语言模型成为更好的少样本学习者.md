# 让预先训练好的语言模型成为更好的少样本学习者

代码：https://github.com/princeton-nlp/LM-BFF

## Abstract

最近的GPT-3模型(Brown et al.， 2020)仅通过利用自然语言提示和一些任务演示作为输入上下文，就实现了出色的少样本性能。

受他们发现的启发，我们在一个更实际的场景中研究少样本学习，我们使用更小的语言模型，微调在计算上是有效的。我们提供了**lm - bff**——更好的语言模型少样本微调——一套用于在少量带注释的示例上微调语言模型的简单且互补的技术。

方法包括(1)**基于提示的微调**，以及自动生成提示的新管道;(2)**为动态地和有选择性**地将演示合并到每个上下文中而改进的策略。

最后，我们提出了一个系统的评估分析少样本性能的一系列NLP任务，包括分类和回归。我们的实验表明，我们的方法结合起来，在这种低资源设置下显著优于标准的微调程序，实现了高达30%的绝对改进，在所有任务中平均提高了11%。我们的方法对任务资源和领域专业知识做了最少的假设，因此构成了一个强大的任务不可知论的少样本学习方法

## Introduction

在这项工作中，我们研究了一个更实际的场景，在这个场景中，我们只假设访问一个中等大小的语言模型，如BERT (Devlin et al.， 2019)或RoBERTa (Liu et al.， 2019)，以及少量的示例(即少样本设置)，我们可以使用这些示例来微调语言模型的权重。

**首先**，我们遵循GPT系列首先提出的基于提示的预测方法进行零样本预测。基于提示的预测将下游任务视为一个(被屏蔽的)语言建模问题，其中模型直接生成针对特定于任务的模板定义的给定提示的文本响应(称为标签词)(参见图1(c))。然而，找到正确的提示需要**领域专业知识和对语言模型内部工作原理**的理解。我们通过引入**自动提示生成**来解决这个问题，其中包括一个经过修剪的蛮力搜索来识别最佳工作标签单词，以及一个新颖的解码目标来使用生成式T5模型自动生成模板

**其次**，我们采用将演示作为附加上下文的想法。我们开发了一个更精细的策略，其中，对于每个输入，我们每次从每个类中随机抽取一个示例，以创建多个最小的演示集。我们还设计了一种新颖的抽样策略，将输入与类似的例子配对，从而为模型提供更有区别的比较。

![image-20231004124044517](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004124044517.png)

## Related Work

**Language model prompting**我们只使用几个带注释的示例作为监督，并通过演示探索自动生成的提示和微调。

**Automatic prompt search**我们的方法搜索模板和标签词，并且能够匹配或优于我们的手动提示。

**Fine-tuning of language models.**我们使用标准的优化技术

**Few-shot learning.**我们的设置也与NLP中的其他少样本学习范式相关联，包括(1)**半监督学习**，其中给出了一组未标记的例子;(2)**元学习**，其中给出了一组辅助任务;(3)**中级培训**，其中给出了相关的中间任务。我们通过对可用资源做最小的假设来偏离这些设置:我们只假设几个注释的示例和一个预先训练的语言模型。

## Problem Setup

**任务制定**：我们假设可以获得一个预先训练的语言模型L，我们希望对一个带有标签空间Y的任务D进行调整。对于任务，我们只假设任务的训练集Dtrain每class有K个训练样本，使样本总数为Ktot = K × |Y|，并且Dtrain = {(xi In, yi)}Ktot i=1。我们的目标是**开发任务无关的学习策略**，这些策略可以很好地推广到一个看不见的测试集(xtest in, ytest) ~ Dtest。为了进行模型选择和超参数调优，我们假设开发集Ddev与少样本训练集相同大小，即|Ddev| = |Dtrain|。这种区别很重要:使用更大的开发集会带来显著的优势，并破坏我们最初从有限数据中学习的目标对于下面所有的实验(除非另有说明)，我们取L = **RoBERTa-large**, K = 16。

**评估数据集**对8个单句和7个句子对英语任务进行了系统研究，其中8个任务来自**GLUE**基准测试， **SNLI**，以及其他6个常用的句子分类任务(**SST-5, MR, CR, MPQA, Subj, TREC**)。对于单句任务，目标是基于输入的句子xin = x1进行预测，例如电影评论是正面还是负面。对于句子对任务，目标是取一对输入句子xin = (x1, x2)，并预测它们之间的关系。

**评估协议**我们测量了5个不同随机采样的Dtrain和Ddev分割的平均性能。

## Prompt-based Fine-tuning

给定一个掩码语言模型L，我们首先将输入xin转换为标识序列~ x，然后语言模型L将标识序列~ x映射为一个隐藏向量序列{hk∈Rd}。~xsingle= [CLS]x1[SEP]或~xpair = [CLS]x1[SEP]x2[SEP]。

对于具有标签空间Y的下行分类任务，我们通过最大化正确标签的log-probability来训练任务特定的头softmax(Woh[CLS])，其中h[CLS]是[CLS]的隐向量，而Wo∈R|Y|×d是一组在微调开始时引入的随机初始化参数。同样，对于一个回归任务，我们可以引入wo∈Rd，优化wo·h[CLS]与金标签之间的均方误差。

解决这个问题的另一种方法是基于提示的微调，在这种方法中，L直接被赋予“自动完成”自然语言提示的任务。例如，我们可以使用输入为x1的提示符(例如，“没有理由看它”)来构建一个二元情感分类任务:

![image-20231004114929087](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004114929087.png)

让L决定[MASK]填“great”(积极)还是“terrible”(消极)更合适。

### Classification

设M: Y→V是从任务标签空间到L的词汇表V中的单个单词的映射，则对于每个xin，设操作xprompt = T(xin)为包含一个[MASK]令牌的蒙面语言建模(MLM)输入。这样，我们就可以把我们的任务看成一个MLM，将类y∈y的预测概率建模为:

![image-20231004115122132](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004115122132.png)

式中，h[MASK]为[MASK]的隐向量，wv为v∈v对应的前softmax向量。当有监督示例{(xin, y)}时，可以对L进行微调，使交叉熵损失最小。值得注意的是，这种方法重用了预先训练的权值wv，并且没有引入任何新的参数。它还减少了预训练和微调之间的差距，使其在少样本场景中更有效。

### Regression

我们假设基本设置与分类相同，但将标签空间Y视为有界区间[vl, vu]。我们将问题建模为两个对立极点{yl, yu}之间的差值，值分别为vl和vu。例如，我们可以将之前的情绪分析任务表述为区间[0,1]内的回归问题，在区间[0,1]内，我们在“terrible”(vl = 0)和“great”(vu = 1)之间滑动。这样，我们可以将y表示为一个混合模型:

![image-20231004124134564](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004124134564.png)

其中p(yu | xin)是yu的概率，p(yl | xin) = 1−p(yu | xin)。然后，我们定义M: {yl, yu}→V，模型p(yu | xin)与Eq.(1)相同。我们对L进行微调，以最小化推断p(yu | xin)与观测的混合权重(y−vl)/(vu−vl)之间的kl发散。

### Manual prompts: the good and the bad

关键的挑战是构建模板T和标注单词M(Y)——我们将这两者统称为提示p。表1总结了我们实验中为每个数据集选择的手动模板和标签词。这些模板和标签词是根据直觉设计的，并考虑了以前文献中使用的格式。

![image-20231004124341425](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004124341425.png)

为了更好地理解是什么构成了一个好的模板或标签词，我们对SST-2和SNLI进行了初步研究。从表2可以看出，不同的提示会导致最终的准确性有很大的差异。具体来说，当模板固定后，标签词与“语义类”匹配得越好，最终的准确率就越高(great/terrible > good/bad > cat/dog)。

![image-20231004124504987](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004124504987.png)

## Automatic Prompt Generation

### Automatic selection of label words

首先研究了如何构造一个标签词映射M，在经过微调后，在Ddev上最大化精度，给出一个固定的模板t。然而，简单地搜索所有可能的赋值(1)通常很难，因为搜索空间的类数是**指数级**的;(2)**易于过度拟合**，因为我们将倾向于发现虚假的相关性，只给出一些注释。

作为一种简单的解决方案，对于每一个类c∈Y，我们利用初始L根据前k个词汇的条件似然性构造一个修剪集Vc⊂V，即设Dc train⊂Dtrain为c类所有实例的子集，取Vc为

![image-20231004124753136](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004124753136.png)

其中PL表示l的输出概率分布。为了进一步缩小搜索空间，我们在修剪后的空间上找到了最大限度地提高Dtrain上零样本精度的最上面n个赋值。然后，我们对所有排名前n的任务进行微调，并使用Ddev重新排序以找到最佳的任务。

### Automatic generation of templates

研究如何从固定的标签词集合M(Y)自动生成不同的模板集合{T}。为了解决这个具有挑战性的问题，我们建议使用**T5** (Raffel et al.， 2020)，一个大型的预先训练的文本到文本转换器。T5被预先训练来填充其输入中缺失的跨度(用T5掩码符号代替，例如<X>或<Y>)。

例如，给定输入“Thank you <X> me to your party <Y> week”，T5被训练生成“<X> For invite <Y> last <Z>”，这意味着“For invite”是<X>的替换，而“last”是<Y>的替换。这非常适合于提示生成:我们可以简单地从Dtrain获取输入句子，并让T5模型构造模板T，而不必为它指定预定义数量的标记。

给定一个输入例子(xin, y)∈Dtrain，我们考虑以下简单的转换，记为Tg(xin, y)，来表示T5模型的输入:

![image-20231004125116980](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004125116980.png)

如图2所示，我们依赖T5模型来填充占位符。在解码时，我们的目标是找到一个对Dtrain中所有例子都适用的输出，即使Σ(xin,y)∈Dtrain log PT5(T | Tg(xin, y))最大化的输出模板T，其中PT5表示T5的输出概率分布。可按以下原则进行分解:

![image-20231004125304372](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004125304372.png)

其中(t1， . . .)t| t|)为模板令牌。

![image-20231004125319612](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004125319612.png)

我们使用波束搜索来解码多个候选模板。具体来说，我们使用宽波束宽度(例如，100)来廉价地获得大量不同的模板。然后，我们在Dtrain上对每个生成的模板进行微调，并使用Ddev选择性能最好的单个模板(表3)，或将前k个模板作为一个整体使用(表4)。而且它也是完全自动化的:与为每个数据集手动调优提示相比，它很容易使用。

![image-20231004125503442](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004125503442.png)

![image-20231004125512301](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004125512301.png)

## Fine-tuning with Demonstrations

### Training examples as demonstrations

我们提出一种更简单的解决方案:在每个训练步骤中，从每个类中随机抽取一个示例（x（c）in，y（c））∈Dtrain，将其转换为T（x（c）in），用M(y(c))代替[MASK] -我们表示为~T（x（c）in，y（c）），然后将其链接（图1c）

![image-20231004130132070](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004130132070.png)

这里⊕表示输入序列的连接。在训练和推理过程中，我们为每个xin采样多个演示集。注意，在训练过程中，xin和演示示例都是从同一个集合Dtrain中采样的。在测试时，我们仍然对来自Dtrain的演示集和所有集合的集合预测进行采样。

### Sampling similar demonstrations

控制演示示例{(x(c) in, y(c))}的构造对于良好的最终性能至关重要。例如，如果其中的对比演示集x(c)in都非常不同(彼此不同，或者与查询xin不同)，那么语言模型就很难解读有意义的模式。

为了解决这个问题，我们设计了一个简单的策略，在这个策略中，我们只选取语义上接近xin的例子。具体来说，我们使用一个预先训练的**SBERT** (Reimers和Gurevych, 2019)模型来获得所有输入句子的嵌入(对于句子对任务，我们使用两个句子的连接)。在这里，我们只是**将没有模板的原始句子输入SBERT**。对于每个查询xin和每个标签c∈Y，我们根据标签x∈Dc的训练实例与查询cos(e(xin)， e(x))的相似度分值对所有训练实例进行排序，并且每个类只有从r = 50%的实例中选取样本用于演示。

## Experiments

### Main results

在实验中使用RoBERTa-large模型，并设置K = 16。在我们的主表中，我们只报告自动模板搜索(这一直是执行得最好的，见表5)。

![image-20231004130915642](C:\Users\阿超\AppData\Roaming\Typora\typora-user-images\image-20231004130915642.png)

为了比较我们的结果，我们比较了一些基线，即(1)在我们的少样本设置中的标准微调;(2)使用全训练集进行标准微调;(3)只上最频繁的课(在完整的训练集上测量);(4)基于提示的零样本预测，我们使用手动提示，使用L“开箱即用”，而不使用任何训练示例;(5)上下文学习中的“GPT-3”，我们使用相同的基于提示的零样本设置，但是用随机取样的32个演示增加上下文(仍然使用RoBERTa-large，而不是GPT-3)。

**Single-prompt results**基于提示的零样本预测比多数类实现了更好的性能，显示了RoBERTa预先编码的知识。基于提示的微调都可以大大超过标准的微调。

**Ensemble results**自动提示搜索的一个优点是，我们可以生成任意多的提示，训练单个模型，并创建大型集合。我们直接比较了在MNLI和RTE(我们共同评估的两个数据集)上搜索的提示和PET的手动提示结果表明，具有多个模板的集成总是能提高性能。与PET的手动提示相比，具有相同数量的自动模板的集成可以获得类似或更好的性能。增加自动模板的数量会带来更多的收益。

## Conclusion

在本文中，我们介绍了LM-BFF，这是一套简单但有效的语言模型微调技术，只使用了几个例子。我们的方法提出(1)使用基于提示的微调与自动搜索提示;并且(2)将选定的任务演示(训练示例)作为输入上下文的一部分。